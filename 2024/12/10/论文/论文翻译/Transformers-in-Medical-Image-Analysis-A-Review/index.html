<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Transformers in Medical Image Analysis A Review | qjl988</title><meta name="author" content="qjl988"><meta name="copyright" content="qjl988"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Transformers in Medical Image Analysis: A Review  Abstract Transformer 在自然语言处理领域占据了主导地位，最近又对计算机视觉领域产生了影响。在医学图像分析领域，Transformer 也已成功应用于全栈临床应用，包括图像合成&#x2F;重建、配准、分割、检测和诊断。我们的论文旨在促进医学图像分析领域对 Transformer 的认识和应">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformers in Medical Image Analysis A Review">
<meta property="og:url" content="https://qjl988.github.io/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Transformers-in-Medical-Image-Analysis-A-Review/index.html">
<meta property="og:site_name" content="qjl988">
<meta property="og:description" content="Transformers in Medical Image Analysis: A Review  Abstract Transformer 在自然语言处理领域占据了主导地位，最近又对计算机视觉领域产生了影响。在医学图像分析领域，Transformer 也已成功应用于全栈临床应用，包括图像合成&#x2F;重建、配准、分割、检测和诊断。我们的论文旨在促进医学图像分析领域对 Transformer 的认识和应">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qjl988.github.io/img/butterfly-icon.png">
<meta property="article:published_time" content="2024-12-10T15:28:34.000Z">
<meta property="article:modified_time" content="2024-12-10T17:03:31.415Z">
<meta property="article:author" content="qjl988">
<meta property="article:tag" content="论文翻译">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qjl988.github.io/img/butterfly-icon.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qjl988.github.io/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Transformers-in-Medical-Image-Analysis-A-Review/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Transformers in Medical Image Analysis A Review',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/loading.gif" data-original="/img/butterfly-icon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">57</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qjl988</span></a><a class="nav-page-title" href="/"><span class="site-name">Transformers in Medical Image Analysis A Review</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Transformers in Medical Image Analysis A Review</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-10T17:03:31.415Z" title="更新于 2024-12-11 01:03:31">2024-12-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">18k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>57分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="transformers-in-medical-image-analysis-a-review"><a class="markdownIt-Anchor" href="#transformers-in-medical-image-analysis-a-review"></a> Transformers in Medical Image Analysis: A Review</h1>
<h2 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h2>
<p>Transformer 在自然语言处理领域占据了主导地位，最近又对计算机视觉领域产生了影响。在医学图像分析领域，Transformer 也已成功应用于全栈临床应用，包括图像合成/重建、配准、分割、检测和诊断。我们的论文旨在促进医学图像分析领域对 Transformer 的认识和应用。具体来说，我们首先概述了内置于 Transformer 和其他基本组件中的注意力机制的核心概念。其次，我们回顾了为医学影像应用量身定制的各种 Transformer 架构，并讨论了它们的局限性。在这篇综述中，我们围绕 Transformer 在不同学习范式中的使用、提高模型效率以及与其他技术的耦合等方面的关键挑战进行了研究。我们希望这篇综述能让医学图像分析领域的读者对 Transformer 有一个全面的了解。</p>
<h2 id="1-introduction"><a class="markdownIt-Anchor" href="#1-introduction"></a> 1 INTRODUCTION</h2>
<p>Transformer [1] 在自然语言处理（NLP）领域占据主导地位，包括语音识别 [2]、合成 [3]、文本到语音的翻译 [4] 和自然语言生成 [5]。作为深度学习架构的一个引人注目的实例，Transformer 最早被引入处理 NLP 中的顺序推理任务。递归神经网络（RNN）[6]（如长短时记忆网络（LSTM）[7]）明确使用序列推理过程，而 Transformer 则通过堆叠的自我注意层显著捕捉序列数据的长期依赖性。通过这种方式，Transformer 既能高效地一次性解决顺序学习问题，又能通过堆叠深度模型而提高效率。在大规模架构上训练的几种 Transformer 架构已在解决 NLP 任务中广泛流行，如 BERT [8] 和 GPT [9], [10] - 仅举几例。</p>
<p><strong>卷积神经网络（CNN）及其变体在一些计算机视觉（CV）任务中达到了最先进的水平[11]，这部分归功于它们逐渐扩大的感受野，可以学习作为语义的结构化图像表征层次。捕捉图像中的视觉语义通常被认为是构建成功计算机视觉网络的核心思想[12]。然而，CNN 忽略了图像中的长期依赖关系，如图像中物体的非局部相关性。Dosovitskiy 等人[13]受上述Transformer在 NLP 中成功应用的启发，提出了视觉Transformer（ViT），将图像分类表述为图像补丁（区域）序列的序列预测任务，从而捕捉输入图像内部的长期依赖关系。ViT 及其衍生实例在多个基准数据集上取得了一流的性能。Transformer 已在图像分类 [13]、检测 [14]、分割 [15]、生成 [16] 和字幕 [17] 等广泛的计算机视觉任务中大受欢迎。此外，Transformer 还在基于视频的应用中发挥着重要作用 [18]。</strong></p>
<p><img src="/img/loading.gif" data-original="images/image-20240201172005406.png" alt="image-20240201172005406" /></p>
<blockquote>
<p>图 1. Transformers 在医学图像分析中的发展。这些图显示了分类、检测、分割和合成应用中选定的方法。</p>
</blockquote>
<p>最近，Transformer 还交叉渗透到医学图像分析领域，用于疾病诊断 [19]、[20]、[21] 和其他临床用途。例如，[22]、[23] 中的作品利用 Transformer 通过计算机断层扫描（CT）或 X 射线图像区分了 COVID19 和其他类型的肺炎，满足了快速有效治疗 COVID-19 患者的迫切需要。此外，Transformer 还成功应用于图像分割[24]、检测[25]和合成[26]，取得了令人瞩目的先进成果。图 1 按时间顺序展示了 Transformer 在不同医学影像应用中的适应性，并将在第 3 节中进一步讨论。</p>
<p>尽管许多研究都致力于将 Transformer 应用于医学图像分析任务，但这种定制化带来的新挑战仍未解决。为了鼓励和促进基于 Transformer 的医学图像分析应用的发展，我们广泛回顾了该领域现有的 170 多种基于 Transformer 的方法，为医学应用提供了解决方案，并展示了 Transformer 在各种临床环境中的应用情况。此外，我们还深入讨论了如何设计基于 Transformer 的方法来解决更复杂的实际任务，包括弱监督/多任务/多模态学习范式。本文包括 Transformer 与 CNN 之间的比较，并讨论了提高 Transformer 网络效率和解释能力的新方法。</p>
<p>以下各节的内容安排如下。</p>
<p>第 2 节介绍 Transformer 的前言及其在视觉领域的发展。</p>
<p>第 3 节回顾了 Transformer 在医学图像分析中的最新应用。</p>
<p>第 4 节讨论了 Transformer 未来的潜在发展方向。</p>
<p>第 5 节为本文的结论。</p>
<h2 id="2-transformers"><a class="markdownIt-Anchor" href="#2-transformers"></a> 2 TRANSFORMERS</h2>
<h3 id="21-preliminaries"><a class="markdownIt-Anchor" href="#21-preliminaries"></a> 2.1 Preliminaries</h3>
<p>典型的 Transformer 利用了神经网络中的注意力机制。因此，我们首先介绍注意力机制的核心原理，然后详细介绍 Transformer 的工作原理。</p>
<h4 id="211-attention-mechanism"><a class="markdownIt-Anchor" href="#211-attention-mechanism"></a> 2.1.1 Attention mechanism</h4>
<p>在日常生活中，人类在探索信息时通常会利用 &quot;注意力机制 &quot;来过滤无关信息，同时关注数据中有意义的部分。受这一观察结果的启发，研究人员为深度学习设计了一种注意力机制，这种机制可以渗入同质数据，同时关注最重要的组成部分或元素。Bahdanau 注意力。</p>
<p>注意力机制最初是由 Bahdanau 等人[27] 针对语言翻译任务提出的，即 Bahdanau 注意力。这种注意力机制是通过所有注释（即编码器生成的每个输入结果）和上一个解码器的加权和来计算的。</p>
<h4 id="212-attention-mechanism-in-computer-vision"><a class="markdownIt-Anchor" href="#212-attention-mechanism-in-computer-vision"></a> 2.1.2 Attention mechanism in computer vision</h4>
<p>计算机视觉领域也提出了类似的概念。例如，Hu 等人[28] 引入了一种新颖的注意力机制，即 “挤压-激发”（Squeeze-and-Excitation），用于执行特征再校准，即强调对特定视觉任务有参考价值的特征，而将其余特征视为不那么重要的特征。</p>
<p><img src="/img/loading.gif" data-original="images/image-20240201173310849.png" alt="image-20240201173310849" /></p>
<blockquote>
<p>图 2. 自注意力机制的简要说明。</p>
</blockquote>
<p><strong>Self-attention.</strong> 在 [1] 中，注意力机制被重新定义为一个处理查询、键和值的函数，这些查询、键和值都来自模块的输入向量，这与 Bahdanau 注意机制不同。输出被定义为值的加权和，其中每个值的权重是根据查询和键之间的注意力计算得出的。</p>
<p>自注意力操作通常以矩阵形式进行，以加速并行计算。为了简要说明自关注度的概念，我们首先以元素形式来描述它。</p>
<p>对于每个输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>c</mi></msup><mo separator="true">,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">x_{i}\in\mathbb{R}^{c},i=1,..,n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.88333em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span></span></span></span>，其对应的查询<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub><mo>∈</mo><msubsup><mi mathvariant="double-struck">R</mi><mi>q</mi><mi>d</mi></msubsup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">q_i\in\mathbb{R}_q^d.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.232216em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mord">.</span></span></span></span>、密钥<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub><mo>∈</mo><msubsup><mi mathvariant="double-struck">R</mi><mi>k</mi><mi>d</mi></msubsup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">k_i\in\mathbb{R}_k^d.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.132216em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.4168920000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mord">.</span></span></span></span> 和值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub><mo>∈</mo><msubsup><mi mathvariant="double-struck">R</mi><mi>v</mi><mi>d</mi></msubsup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">v_i\in\mathbb{R}_v^d.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.096108em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord">.</span></span></span></span> 向量分别通过参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>q</mi></msup></mrow><annotation encoding="application/x-tex">W^q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">W^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>v</mi></msup></mrow><annotation encoding="application/x-tex">W^v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span></span></span></span> 生成。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.15999999999999992em" columnalign="right left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>q</mi><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo>×</mo><msup><mi>W</mi><mi>q</mi></msup><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msup><mi>W</mi><mi>q</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>c</mi><mo>×</mo><msub><mi>d</mi><mi>q</mi></msub></mrow></msup><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>k</mi><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo>×</mo><msup><mi>W</mi><mi>k</mi></msup><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msup><mi>W</mi><mi>k</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>c</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>v</mi><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo>×</mo><msup><mi>W</mi><mi>v</mi></msup><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msup><mi>W</mi><mi>v</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>c</mi><mo>×</mo><msub><mi>d</mi><mi>v</mi></msub></mrow></msup><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>d</mi><mi>q</mi></msub><mo>=</mo><msub><mi>d</mi><mi>k</mi></msub><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{rl}q_i=x_i\times W^q,&amp;W^q\in\mathbb{R}^{c\times d_q},\\k_i=x_i\times W^k,&amp;W^k\in\mathbb{R}^{c\times d_k},\\v_i=x_i\times W^v,&amp;W^v\in\mathbb{R}^{c\times d_v},\\d_q=d_k.\end{array}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.827324em;vertical-align:-2.163662em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.663662em;"><span style="top:-4.814554em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-3.6054459999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-2.396338em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-1.1963380000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.163662em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.663662em;"><span style="top:-4.814554em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285716em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-3.6054459999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-2.396338em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9636619999999998em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p>
<p>输出也是一个概率，由计算出的加权值的加权和计算得出、</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mrow><mi mathvariant="normal">S</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">f</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">x</mi></mrow><mo stretchy="false">(</mo><mfrac><msubsup><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mfrac><msubsup><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo></mrow><mrow><munder><mo>∑</mo><mi>j</mi></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mfrac><msubsup><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\alpha_{ij}=\mathrm{Softmax}(\frac{\alpha_{ij}^{\prime}}{\sqrt{d_k}})=\frac{\exp(\frac{\alpha_{ij}^{\prime}}{\sqrt{d_k}})}{\sum_j\exp(\frac{\alpha_{ij}^{\prime}}{\sqrt{d_k}})}.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.466664em;vertical-align:-0.93em;"></span><span class="mord"><span class="mord mathrm">S</span><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.07778em;">f</span><span class="mord mathrm">t</span><span class="mord mathrm">m</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.536664em;"><span style="top:-2.25278em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7847720000000002em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.441336em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.6948600000000003em;vertical-align:-1.57996em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.1149em;"><span style="top:-2.14494em;"><span class="pstrut" style="height:3.1869em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16195399999999993em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.15196em;"><span style="top:-2.5864385em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622307142857143em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222307142857144em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17776928571428574em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.63282em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7416285714285715em;"><span style="top:-2.177714285714286em;margin-left:-0.0037em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span><span style="top:-3.4169em;"><span class="pstrut" style="height:3.1869em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-4.1149000000000004em;"><span class="pstrut" style="height:3.1869em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1869em;"><span style="top:-2.5864385em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622307142857143em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222307142857144em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17776928571428574em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.60742em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.214em;margin-left:-0.0037em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.42488571428571426em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.57996em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">.</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><msub><mi>q</mi><mi>i</mi></msub><mo>×</mo><msubsup><mi>k</mi><mi>j</mi><mi mathvariant="normal">T</mi></msubsup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\alpha_{ij}^{\prime}=q_i\times k_j^\mathrm{T},
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.274439em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.891331em;"><span style="top:-2.4530000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 衡量输入的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 个元素对输出的第$ i$ 个元素的贡献。通过这一操作，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>被视为分配给元素 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的关注度。因此，最终的输出关注度可以按以下方式计算为所有值的加权和：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><munder><mo>∑</mo><mi>j</mi></munder><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>×</mo><msub><mi>v</mi><mi>j</mi></msub><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">z_i=\sum_j\alpha_{ij}\times v_j.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.463782em;vertical-align:-1.413777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.413777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">.</span></span></span></span></span></p>
<p>元素自关注度可以扩展到矩阵。在大多数情况下，每个输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的查询 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、键<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">k_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 都是通过并行矩阵计算生成的。让 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>s</mi><mo>×</mo><mi>c</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X\in\mathbb{R}^{s\times c}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.771331em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">c</span></span></span></span></span></span></span></span></span></span></span></span> 表示输入矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 表示查询矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 表示密钥矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 表示值矩阵，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> 是样本数，每个矩阵由元素组成，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">;</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">;</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">;</mo><msub><mi>x</mi><mi>s</mi></msub><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">X=[x_{1};x_{2};\cdots;x_{s}]^{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span> 。同样，我们计算注意力矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> 和输出矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> 的方法如下、</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo>=</mo><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo>×</mo><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo separator="true">,</mo><mi>K</mi><mo>×</mo><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo separator="true">,</mo><mi>V</mi><mo>×</mo><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">Z_i=\text{Attention}(Q\times W_i^Q,K\times W_i^K,V\times W_i^V),
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9592389999999998em;"><span style="top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.138331em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="sans-serif">M</mi><mi mathvariant="sans-serif">u</mi><mi mathvariant="sans-serif">l</mi><mi mathvariant="sans-serif">t</mi><mi mathvariant="sans-serif">i</mi><mi mathvariant="sans-serif">H</mi><mi mathvariant="sans-serif">e</mi><mi mathvariant="sans-serif">a</mi><mi mathvariant="sans-serif">d</mi></mrow><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mi mathvariant="sans-serif">C</mi><mi mathvariant="sans-serif">o</mi><mi mathvariant="sans-serif">n</mi><mi mathvariant="sans-serif">c</mi><mi mathvariant="sans-serif">a</mi><mi mathvariant="sans-serif">t</mi></mrow><mo stretchy="false">(</mo><msub><mi>Z</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>Z</mi><mi>h</mi></msub><mo stretchy="false">)</mo><msup><mi>W</mi><mi>O</mi></msup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\mathsf{MultiHead}(Q,K,V)=\mathsf{Concat}(Z_1,\cdots,Z_h)W^O,
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathsf">M</span><span class="mord mathsf">u</span><span class="mord mathsf">l</span><span class="mord mathsf">t</span><span class="mord mathsf">i</span><span class="mord mathsf">H</span><span class="mord mathsf">e</span><span class="mord mathsf">a</span><span class="mord mathsf">d</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathsf">C</span><span class="mord mathsf">o</span><span class="mord mathsf">n</span><span class="mord mathsf">c</span><span class="mord mathsf">a</span><span class="mord mathsf">t</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span></span></p>
<p>**Multi-head self-attention.**文献 [1] 中的研究表明，对同一输入应用多个自注意力可以更好地捕捉分层特征。这些自注意力层的工作原理与卷积层中的多核类似。在给定 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span></span></span></span> 个自注意力（头部）的情况下，模块通过连接计算出的注意力输出最终结果。</p>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo separator="true">,</mo><msubsup><mi>W</mi><mi>i</mi><mi>J</mi></msubsup><mo separator="true">,</mo><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup></mrow><annotation encoding="application/x-tex">W_i^Q,W_i^J,W_i^V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.959239em;"><span style="top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span> 表示线性投影矩阵，分别将矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mtext>、</mtext><mi>K</mi><mtext>、</mtext><mi>V</mi></mrow><annotation encoding="application/x-tex">Q、K、V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord cjk_fallback">、</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord cjk_fallback">、</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>映射到不同的子空间。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span> 是输出投影矩阵，它将所有注意力头的自我注意力输出汇总在一起。</p>
<h3 id="22-architecture"><a class="markdownIt-Anchor" href="#22-architecture"></a> 2.2 Architecture</h3>
<p><img src="/img/loading.gif" data-original="images/image-20240201173210530.png" alt="image-20240201173210530" /></p>
<blockquote>
<p>图 3. 典型 Transformer 架构的简要说明 [29]。</p>
</blockquote>
<p>在 [1] 中，作者提出了一种典型的编码器-解码器结构的 Transformer 网络。编码器将输入序列 {x1, . , xn} 映射到相同长度的输出序列 {z1, - - , zn}。解码器根据编码后的 z 表示，以元素为单位生成输出 {y1, - - , ym}，并将之前的输出作为额外的输入。典型的 Transformer 架构如图 3 所示，下文将对其进行介绍。</p>
<h4 id="221-encoder"><a class="markdownIt-Anchor" href="#221-encoder"></a> 2.2.1 Encoder</h4>
<p>典型 Transformer 中的编码器有 n = 6 个堆叠块，由两种类型的层组成，即多头注意层和前馈层。残差连接层和层归一化层也与上述层结合在一起。具体来说，在每个区块中，首先计算多头注意力，然后进行层归一化，计算多头注意力的输入和输出之和。然后，执行前馈层，再对前馈层的输入和输出之和进行分层归一化。</p>
<h4 id="222-decoder"><a class="markdownIt-Anchor" href="#222-decoder"></a> 2.2.2 Decoder</h4>
<p>解码器也有 n = 6 个区块，与编码器类似，但略有改动。具体来说，在编码输出的顶部插入了一个额外的自注意层。由于预测是基于已知的状态，因此在第一个自保持层中采用了屏蔽技术，以阻断后续对前一位置状态的贡献。在解码器输出之后插入一个线性层和一个 Softmax 层，以生成最终输出。</p>
<h3 id="23-vision-transformer"><a class="markdownIt-Anchor" href="#23-vision-transformer"></a> 2.3 Vision Transformer</h3>
<p>Transformer 在 NLP 领域的成功传播到了计算机视觉（CV）研究领域，该领域已经做出了许多努力，使 Transformer 适应视觉任务。到目前为止，基于Transformer的视觉模型已经以前所未有的速度发展起来，其中最有代表性的是DEtection TRansformer（DETR）[14]、Vision Transformers（ViT）[13]、Data-efficient image Transformers（DeiT）[30]和Swin-Transformer[31]。DETR 由 Carion 等人提出的 DETR[14]是第一个将Transformer应用于 CV 任务的作品，特别是用于物体检测任务。与传统的物体检测方法不同，DETR 是一种端到端的检测模型，它利用Transformer编码器来模拟 CNN 骨干网提取的图像特征之间的关系，利用Transformer解码器来生成物体查询，并利用前馈网络来分配标签和绑定物体周围的方框。</p>
<p><img src="/img/loading.gif" data-original="images/image-20240201173504548.png" alt="image-20240201173504548" /></p>
<blockquote>
<p>图 4. ViT 的典型架构 [13]。它使用顺序图像块作为输入，使用 Transformer Encoder 对其进行处理，并通过 MLP 头输出类预测。 Transformer 编码器由 N 个 Transformer 块构建。</p>
</blockquote>
<p>**ViT。**继 DETR 之后，Dosovitskiy 等人[13] 提出了视觉Transformer（ViT），如图 4 所示。ViT 是一种图像分类模型，基本采用了传统 Transformer 的架构。在 ViT 中，输入图像被转换成一系列补丁，每个补丁都与位置编码方法相结合，对每个补丁的空间位置进行编码，以提供空间信息。然后，补丁与类标记一起被输入 Transformer，以计算 MHSA 并输出学习到的补丁嵌入。ViT 输出的类标记状态可作为图像表示。最后，使用多层感知（MLP）对学习到的图像表示进行分类。除了原始图像，CNN 的特征图也可以输入 ViT 进行关系映射。</p>
<p><strong>DeiT.</strong> 为了解决 ViT 所需的大规模训练数据问题，Touvron 等人[30] 提出了 DeiT，以确保其在小规模数据上的性能。他们采用了师生配制的知识蒸馏框架，在输入序列后附加一个蒸馏标记（这是一个术语，指 Transformer），从教师模型的输出中学习。此外，他们还认为，利用 CNN 作为教师模型可以促进作为学生网络的 Transformer 继承归纳偏差的训练。</p>
<p>**Swin-Transformer。**为了降低计算高分辨率图像注意力的成本，并处理场景理解任务（如分割）中不同大小的补丁，Liu 等人[31] 提出了 Swin-Transformer 方法。他们引入了窗口自注意力来降低计算复杂度，并使用移动窗口注意力来模拟跨窗口关系。此外，他们还将这些注意块与补丁合并块连接起来，用于合并相邻的补丁，从而产生一种分层表示法，以处理视觉实体尺度的变化。</p>
<h3 id="24-other-techniques"><a class="markdownIt-Anchor" href="#24-other-techniques"></a> 2.4 Other techniques</h3>
<p>同时，近期的一些研究也验证了基于 MLP 的模型，并考察了 CNN 或 ViT 中注意力机制、卷积和其他模块的有效性。虽然 CNN 和 ViT 在相当长的一段时间内占据主导地位，但一些基于 MLP 的模型的成功也引起了巨大反响。MLPPMixer [32] 就是其中的代表作。MLP-Mixer 由 Tolstikhin 等人[32] 于 2021 年 5 月提出，它采用了简单的纯深度 MLP 架构，但表现出了极具竞争力的性能。MLPMixer 采用按补丁扁平化而非完全扁平化，同时不像 ViT 那样在补丁序列中添加位置编码和类标记。在补丁嵌入学习之后，混合器 MLP 块由令牌混合 MLP 和通道混合 MLP 组成，前者用于聚合补丁间特征，后者用于整合补丁内特征。最终的类别将根据全局平均池化后获得的特征进行预测。</p>
<p>与 MLP-Mixer 同时或之后，许多其他基于 MLP 的模型也被提出，如 gMLP [33]、ResMLP [34]、ASMLP [35]、CycleMLP [36]等。MLP-Mixer 不仅启发了人们对基于 MLP 的模型的进一步探索，还推动了 CV 神经架构的进一步发展。由于 Transformer、CNN 和 MLP 在性能上相互竞争，目前仍没有证据表明哪种架构更适合特定的 CV 学习任务。对于医学图像分析，我们还将在第 4 节 C 部分讨论 CNN 和 Transformer 的比较。</p>
<h2 id="3-transformers-in-medical-image-applications"><a class="markdownIt-Anchor" href="#3-transformers-in-medical-image-applications"></a> 3 TRANSFORMERS IN MEDICAL IMAGE APPLICATIONS</h2>
<p><img src="/img/loading.gif" data-original="images/image-20240201174424967.png" alt="image-20240201174424967" /></p>
<blockquote>
<p>图 5. Transformers 在医学图像分析中的应用，如本工作所述。</p>
</blockquote>
<p>Transformer已广泛应用于全栈临床应用。在本节中，我们首先介绍基于 Transformer 的医学图像分析应用，包括分类、分割、图像到图像的转换、检测、配准以及基于视频的应用。我们根据学习任务对这些应用进行分类，如图 5 所示。</p>
<h3 id="31-classification"><a class="markdownIt-Anchor" href="#31-classification"></a> 3.1 Classification</h3>
<p><img src="/img/loading.gif" data-original="images/image-20240201174533344.png" alt="image-20240201174533344" /></p>
<blockquote>
<p>表 1 用于医学图像分类任务的 Transformer。</p>
</blockquote>
<p>利用 Transformer 进行疾病诊断和预后的方法都被制定为分类任务，可分为三类，包括：</p>
<ul>
<li>将 ViTs 直接应用于医学图像；</li>
<li>将 ViTs 与卷积相结合，以实现更具代表性的局部特征学习；</li>
<li>将 ViTs 与图表示相结合，以更好地处理复杂数据。</li>
</ul>
<p>本节将全面介绍用于医学图像分类任务的上述三类 Transformer（表 1）。</p>
<h4 id="311-applications-of-pure-transformers"><a class="markdownIt-Anchor" href="#311-applications-of-pure-transformers"></a> 3.1.1 Applications of pure Transformers</h4>
<p>我们把类似于最初提出的 ViT [13] 称为纯粹的 Transformer。这些方法通常不包含重大的结构变化。我们按图像模式介绍纯Transformer的文献，如 X 光[48]、[44]、计算机断层扫描[20]、[19]、磁共振成像[21]、超声波[61]、OCT[71]等。</p>
<p>X 射线。X 射线是一种廉价、便捷的成像技术，被广泛应用于多种疾病的筛查和诊断，如乳腺癌、肺炎、骨折等，特别是在 COVID-19 大流行期间，X 射线在疾病筛查中发挥了非常重要的作用，因此是人工智能研究人员在设计基于 Transformer 的方法时常用的一种模式。Liu 等人[48] 提出了 Vision Outlooker (VOLO)，这是一种 ViT 模型，用 outlooker attention 取代了原有的注意机制[72]。他们的模型在诊断 COVID-19 时达到了最先进（SOTA）的性能，而无需在 ImageNet 上进行预训练。Shome 等人[50] 提出了一种基于 ViT 的 COVID-19 诊断模型，方法是在自收集的大型 COVID-19 胸部 X 光图像数据集上训练该模型。他们还使用 Grad-CAM [73] 来显示 COVID-19 的进展。Krishnan 等人[51] 以胸部 X 光图像的斑块为输入，应用经过 ImageNet 训练的 ViT-B/32 网络来区分 COVID-19。尽管 ViT 对 COVID-19 很有效，Tanzi 等人[44] 还是应用 ViT 模型对股骨骨折进行了分类。他们的研究利用聚类方法验证了 ViT 提取特征的能力，并将其性能与 CNN 进行了比较。上述模型揭示了大数据规模数据集的重要性，它能增强 Transformer 的性能。因此，由于 COVID-19 相关任务[48]、[50]、[73]、[51] 的数据集规模大于股骨骨折任务[44]，COVID-19 相关任务的性能也更高。</p>
<p>计算机断层扫描。基于气体和组织之间的高对比度，CT 通常用于胸部疾病诊断。因此，纯 Transformer 对 CT 图像的应用主要集中在胸部疾病方面。例如，Than 等人[40] 研究了用于 COVID-19 和肺部疾病分类任务的 ViT 补丁大小。他们发现，补丁尺寸越大，性能越低，这表明局部信息和全局信息之间存在权衡，而 32 × 32 补丁的准确率最高。Costa 等人[22] 建议使用 ViT 及其变体来区分 COVID-19 肺炎和其他肺炎与正常病例。通过比较几种模型的性能，他们发现数据高效图像Transformer（DeiT）[30] 等预训练模型取得了有竞争力的结果。同时，传统的 ViT 及其使用 Performer 编码器的变体即使没有经过预训练也取得了很好的效果。Li 等人[39] 设计了一个基于 ViT 的 COVID-19 诊断平台。他们将 CT 图像转换成一系列扁平化的斑块，以适应 ViT 的诊断输入。他们还采用了师生模型，从自然图像预训练的 CNN 中提炼知识。Gao 等人[19] 将 ViT 应用于二维和三维 CT 扫描，以诊断 COVID-19。他们建议通过提取固定数量的切片来构建图像子卷，从而对切片数量不同的成像序列进行 &quot;归一化 &quot;处理。他们还证明，ViT 的性能优于具有竞争力的 CNN 模型 DenseNet。Zhang 等人[20] 在 CT 图像上训练了流行的 Swin-Transformer 。具体来说，该框架首先通过 Unet 对肺部进行分割，然后将肺部区域输入特征提取器。这种策略有助于减轻 Transformer 框架的计算负担。上述研究表明，由于 CT 图像比 X 射线图像更难获取，因此预训练对于 CT 图像分类任务非常重要。此外，由于 CT 图像体积庞大，通过注意力机制降低计算复杂度的方法对 CT 图像至关重要。</p>
<p>磁共振成像 磁共振成像（MRI）具有更好的成像质量，尤其适用于包括血管和神经在内的细微解剖结构，但其获取耗时较长。由于核磁共振成像是一种强大的非侵入性软组织成像技术，因此常用于神经成像研究。例如，He 等人[21] 提出了一种用于脑年龄估计的双通道网络。全局通路旨在捕捉大脑核磁共振成像的全局上下文信息，而局部通路则负责捕捉局部斑块的细粒度信息。然后，通过全局-局部注意机制融合局部和全局上下文表征。接下来，融合后的特征和局部斑块会被送入一个经过修订的全局-局部 Transformer。此外，核磁共振成像的临床应用范围很广，例如癌症诊断，这使其成为训练 ViT 的有力候选模式。</p>
<p>超声波 使用护理点 (POC) 的超声波扩大了适用范围，因为获取图像不需要特定的位置。Perera 等人[61] 的研究提出了一种基于 Transformer 的架构，可根据超声片段诊断 COVID-19。为确保内存和时间效率，他们提出用 Linformer 代替标准 ViTs，将空间时间复杂度从传统自我注意机制的 O(n2) 降低到 O(n)。此外，超声以其易用性、低成本和安全性成为乳腺癌成像的重要方式。Gheflati 等人[62] 利用 ViTs 对超声图像中的正常、恶性和良性乳腺组织进行了分类。他们还比较了不同配置的 ViT 与 CNN 的性能，以证明其效率。</p>
<p>其他 除上述成像模式外，其他成像技术也被用于特定疾病的检查和诊断，如皮肤镜图像[66]、眼底图像[74]、组织病理学图像[59]。例如，Xie 等人[66] 利用皮肤镜图像检测黑色素瘤。他们建议将 Swin-Transformer 与无参数注意力模块 SimAM 结合起来，为目标分类任务学习更好的特征。考虑到输入分类器的特征包含丰富的语义信息但缺乏细节信息，他们将前三个 Swin-Transformer 块的输出分别设计为三个 SimAM 块的输入，然后将包括最终特征图在内的所有 SimAM 块输出串联在一起形成新的最终特征图，作为最终分类层的输入。Li 等人[67] 评估了 Transformer 在医学图像分析中的分布外检测任务上的性能。他们的工作包括原始的视觉Transformer和具有多头、软蒸馏和硬蒸馏的数据高效图像Transformer。这些模型在皮肤病变数据集 HAM10000 和 DermNet 上的表现显示了 Transformer 在 OOD 检测任务中的有限性能和安全关键问题。Ikromjanov 等人[59] 应用 ViT 协助病理学家根据格里森分级系统对整张组织病理图像上的前列腺癌（PCa）进行分级，结果令人鼓舞。</p>
<p>如表 1 所示，尽管纯 Transformer 在 COVID-19 XRays 等几个案例中表现出色，但在其他任务中也有必要进一步开发。</p>
<h4 id="312-applications-of-hybrid-transformers"><a class="markdownIt-Anchor" href="#312-applications-of-hybrid-transformers"></a> 3.1.2 Applications of hybrid Transformers</h4>
<p>尽管纯粹的 ViT 不需要太多修改就能取得很好的效果，但人们仍在努力探索将 ViT 与其他学习组件相结合，以更好地捕捉复杂的数据分布或获得更好的性能。典型的案例是 Transformer 与 1) 卷积层和 2) 图表示的组合。接下来，我们将介绍这两个类别。带有卷积层的 Transformer。视觉Transformer更注重数据内部全局关系的建模，而传统的 CNN 则更关注局部纹理。这种差异促使研究人员将视觉Transformer和 CNN 的优势结合起来。此外，医学图像分析不仅涉及图像中各区域的相关性，还涉及微妙的纹理。因此，许多研究都致力于探索这种 CNN-ViT 组合。</p>
<p>大多数应用集中在胸部疾病的诊断上，尤其是 COVID-19 或其他相关疾病。Van 等人[23] 利用 ViT 的特征整合能力，使用 Transformer 对未注册的医学图像进行多视角分析，对胸部 X 光片进行分类。他们提出了基于 Transformer 的方法，通过可训练的注意力机制，在特征层考虑不同视图的空间信息。他们将 Transformer 应用于 CNN 生成的中间特征图，以检索一个视图中的特征，并将其转移到另一个视图中。因此，无需像素对应，就能为原始视图添加额外的上下文。他们的研究还提出用较少的视觉标记来替代源像素，从而降低了计算复杂度。Verenich 等人[45] 将 ViTs 中的全局空间信息引入 CNN，用于肺病分类，同时保持空间不变性和等差性。Liang 等人[37] 利用 CNN 挖掘有效特征，并利用 Transformer 进行特征聚合。此外，他们还采用了有效的数据采样策略来减少输入的大小，同时保留足够的诊断信息。Park 等人[43] 为 COVID-19 诊断设计了一个预训练 CNN 主干网和一个 ViT。模型预训练使用了大规模的 CXR 分类公共数据集。对于胸腔疾病分类这一简单任务，现有方法简单而有效，即先使用 CNN 提取特征，然后使用 Transformer 捕捉高级信息。</p>
<p>除 COVID-19 诊断外，Yassine 等人[38] 通过将提取的特征输入 ViT，将多个 CNN 与 ViT 结合起来。他们将 CNN 的数量及其预训练配置与 CNN-ViT 混合模型进行了比较。值得一提的是，他们在 ImageNet 数据集生成的图像上对 CNN 进行了预训练[12]，使用的是在脑 CT 图像上预训练的生成对抗网络 (GAN)。他们声称，在生成的图像上进一步预训练，可以为目标计算机断层扫描数据集带来更好的归纳偏差，因为两个域的不相似性降低了。Zhao 等人[53]考虑利用 CNN 和 Transformer 的组合，使用多相对比增强磁共振成像（CEMRI）对肝细胞癌（HCC）进行多指标量化。他们提出了 mrTrans-Net，其中有三个并行编码器，每个编码器后都有一个非本地 Transformer，从动脉相位、PV 相位和延迟相位提取特征。接着，添加一个相位感知 Transformer，以量化每个相位与目标多相 CERMI 信息融合和选择的相关性。量化不仅在相位感知 Transformer 之后进行，还在那些非局部 Transformer 之后进行，以形成一个增强的损失函数来约束量化任务。Jiang 等人[65] 将 ViTs 和 CNNs 视为基础学习器，探索了集合学习的有效性，以根据 B 淋巴细胞前体和白血病 B 淋巴细胞的显微图像诊断急性淋巴细胞白血病。他们提出了一种基于 ViT 和 EfficientNet 的集合模型。由于这两个基础模型是互补的，因此集合结果显示出了一定的改进。他们还提出了一种数据增强方法，以处理每幅图像中正常细胞/癌细胞不平衡的问题。Chen 等人[56] 提出了多尺度视觉 Transformer 模型，如图 6 所示，称为 GasHis-Transformer，用于处理胃组织病理学图像分类。他们设计了全局信息模块（GIM）和局部信息模块（LIM）（基于 CNN）来提取特征。此外，他们还借鉴了 InceptionV3 的并行结构来学习多尺度局部表征。此外，他们的模型对十种不同的对抗性攻击或传统噪声具有鲁棒性，并可推广到其他癌症组织病理学图像分类任务中。Gao 等人[55] 提出了基于实例的 Vison Transformer（iViT），用于乳头状肾细胞癌的亚型分类。iViT 首先从实例级斑块中提取并选择实例特征，这些斑块包括一个核、周围背景的一部分以及核的等级。然后，它汇总这些特征，进一步捕捉细胞级和细胞层级特征。最后，该模型将这两种精细获取的特征编码到最终的图像级表示中，其中嵌入了等级和位置，以便进行子类型划分。Wang 等人[54] 提出了一种 3D Transformer，以超越 3D CNN。他们利用三维卷积层提取三维块的特征，并利用师生网络从 CNN 教师那里学习 Transformer 权重。Xia 等人[42] 提出了用于胰腺癌筛查的解剖感知 Transformer，并证明赢得了放射科医生的青睐。Zeid 等人[57] 在公开的 CRC 组织学数据集上验证了 ViTs 及其变体 Compact Convolutional Transformer 在多类结直肠癌（CRC）组织学图像分类任务中的有效性。Zhao 等人[60] 将驯服Transformer与 T2T-ViT 相结合，处理了宫颈癌分类任务中图像质量不一致的不平衡样本。Yu 等人[68] 采用 Transformer 编码器对皮肤病变特征之间的依赖性进行建模，以检测黑色素瘤识别中的丑小鸭标志。Yang 等[70] 通过联合采用 CNN 和 Transformer 模型，提出了一种 Transformer Eye（TransEye）细粒度眼底疾病图像分类。Wu 等人[69] 提出了 ScATNet，用于在多个输入尺度上对斑块间和尺度间表示建模，以诊断活检图像中的黑色素细胞病变。这些用于各种应用的混合 Transformer 包含丰富的创新，包括结构改进、设计新颖的 ViT 模块、CNN 模块，以及预训练和集合的学习策略。</p>
<p>带图的 Transformer。图学习是 MIA 中的常见做法。图学习的核心概念是学习每个样本的紧凑表示（如嵌入），同时通过数据图保留样本间的内在关系[75]。作为一种基于注意力的网络，Transformer 适合对图数据进行操作，包括聚合节点特征和计算节点关系。</p>
<p>在网络神经科学领域，大脑网络被建模为一个图，其中每个节点表示一个感兴趣的解剖区域（ROI），连接两个节点的边表示它们之间的相互作用（如神经发射）。大脑图谱在促进我们了解大脑作为高度相互关联的系统在健康和疾病中的作用方面发挥着重要作用[76], [77]。Kim 等人[52]的研究利用了功能连接（FC）网络的动态特性，将动态特征整合到紧凑的脑图表示中。具体来说，他们提出了时空注意力图同构网络（STAGIN），用于学习具有时空注意力的大脑连接组的动态图表示。GNN 用于在每个时间步提取大脑功能连接组的图级表示。最后，模型使用 Transformer 编码器获得动态图序列的最终表示。具体来说，他们将编码的时间戳与节点特征串联起来，以嵌入时间信息。他们声称，Transformer 的使用不仅提高了分类性能，还改善了时空可解释性。这类方法验证了 Transformer 在挖掘复杂图的特征和关系两方面的能力，从而引起了更多人对这一方法的关注。</p>
<p>我们对 Transformer 在医学图像分类任务中的应用总结如下：</p>
<p>与 CNN 相比，Transformer 在大多数任务中都取得了相当或更好的性能。</p>
<p>Transformer 对大规模数据集有一定的渴求，这在一定程度上限制了其适用性，尤其是在医学图像分析领域。预训练可以作为缓解这一问题的替代方案。</p>
<p>在大型图像上训练 Transformer 时，计算负担很重。因此，降低模型复杂度和开发轻量级模型是提高其效率的关键因素。</p>
<p>混合 Transformer 从传统网络（即 CNN 和 GNN）和 Transformer 两方面都获益匪浅，因此受到越来越多的关注。</p>
<h3 id="32-segmentation"><a class="markdownIt-Anchor" href="#32-segmentation"></a> 3.2 Segmentation</h3>
<p>基于 Transformer 的方法还被应用于多种分割任务，包括腹部多器官分割 [83]、[84]、[85]、[87]、[102]、[25]、[118]、[119]、[124]、[126]、[98]、[111]、[99]、[91]、[101]、胸部多器官分割 [119]、心脏分割 [83]、 [85]、[89]、[92]、[102]、[118]、[124]、[126]、[127]、[111]、[99]、[91]、[101]、胰腺分割[86]、[123]、脑肿瘤/组织分割[87]、 [93], [105], [112], [123], [128], [129], [130], [131], [132], [122], [113], [91], [133], [134], 息肉分割 [96], [108]、 [125], [135], [136], 肝脏和肝脏病变分割 [98], [137], [138], [139], [122], [91], [140], 肾脏肿瘤分割 [138], [91], 皮肤病变分割 [96], [108], [114], [125], [141], [122], [136], 前列腺分割 [96], [140], 腺体分割 [24], [105]、 [125]、[114]、[100]、细胞核分割[24]、[105]、[114]、[125]、[100]、细胞分割[108]、[142]、[143]、脾脏分割[112]、肺野/COVID-19 肺炎病灶分割[114]、视网膜血管分割[144]和高光谱病理图像分割[145]。表 2 详细列出了几种杰出的方法。</p>
<p>在大多数医学图像分割任务中，被称为 Unet 的 U 型卷积神经网络架构取得了巨大成功。然而，由于使用卷积操作，Unet 在模拟长期依赖关系方面也受到了限制。为了克服这一局限，研究人员在设计与 Unet 架构相结合的鲁棒混合 Transformer 方面做出了努力，这将在第一部分中介绍。此外，也有几种方法将纯 Transformer 应用于分割任务，将在本节的第二部分介绍。</p>
<h4 id="321-hybrid-transformers"><a class="markdownIt-Anchor" href="#321-hybrid-transformers"></a> 3.2.1 Hybrid Transformers</h4>
<p>为了构建与流行的 U 型架构相匹配的 Transformer，我们发现现有研究最关注以下三个问题，包括</p>
<p>在 U 型架构的不同层次插入 Transformer 层；</p>
<p>使用不同的策略将 Transformer 和 CNN 结合起来；</p>
<p>使用多尺度特征或注意力机制。</p>
<p>下面我们将分别详细介绍这三类研究。</p>
<h5 id="location-of-transformer-in-u-shaped-architecture"><a class="markdownIt-Anchor" href="#location-of-transformer-in-u-shaped-architecture"></a> Location of Transformer in U-shaped architecture.</h5>
<p>要在 U 型架构中插入 Transformer 层，一个直观的想法是在编码器和解码器模块之间插入一个完整的 Transformer，以建立高层次视觉概念之间的长期依赖关系。按照这一思路，Chen 等人[83] 提出了 TransUNet，如图 7 所示，它通过 CNN 提取高分辨率空间特征，然后通过 Transformer 对全局上下文进行编码。然后将 Transformer 编码的自注意特征进行上采样，并与利用跳接从编码路径中提取的多尺度特征相结合，以实现精确定位。与 V-Net、AttnUNet 和 ViT 相比，TransUNet 在多器官和心脏分割任务中取得了优异的性能。与 TransUNet 类似，Yao 等人[84] 将 Transformer 网络与 Claw Unet 架构相结合，在突触多器官分割中的表现优于 TransUnet。又如，Xu 等人[85] 提出了 LeViT-UNet，将 LeViT Transformer 集成到 Unet 架构中。在[86]中，Sha 等人通过在 Unet 中添加 Transformer 模块设计了 Transformer-Unet，其性能优于 TransUnet。</p>
<p>与上述在编码器模块后直接插入 Transformer 的研究不同，Li 等人[87] 在解码器中加入了注意力升采样（AU）组件。他们还提出了在局部窗口工作的窗口注意力解码器（WAD）和窗口注意力升采样（WAU），以减少内存和计算成本。Gao 等人[89] 提出的UTNet 在编码器和解码器模块中都应用了自注意模块，以最小的开销捕捉多尺度的长距离依赖关系。他们提出了一种高效的自注意机制以及相对位置编码，从而将自注意操作的复杂度从 O(n2) 显著降低到近似 O(n)。他们工作的升级版，即 UTNetV2 [92]，进一步提出了高效的双向注意（BMHA）。Fu 等人[91] 提出了 TF-Unet，它是建立在卷积和 Transformer 多尺度交织的骨干上的。此外，还有一些作品提出了改进特征串联的策略[127]、[98]。</p>
<h5 id="strategies-of-bridging-transformer-and-cnn"><a class="markdownIt-Anchor" href="#strategies-of-bridging-transformer-and-cnn"></a> Strategies of bridging Transformer and CNN.</h5>
<p>与上述在单一推理路径中结合 Transformer 和 U 形架构的方法不同，其他作品探索了不同的 TransformerCNN 耦合策略。Sun 等人[93] 使用 Unet 和 Transformer 编码器独立生成表示，然后整合它们的表示进行后续解码。同样，Li 等人[170] 提出了 X-Net，使用 CNN 和 Transformer 同时提取局部和全局特征。Zhang 等人[96] 提出的 TransFuse 也是以并行的方式将 Transformer 和 Unet 结合在一起。比上述研究更好的是，他们提出了一种新颖的融合技术，即 BiFusion 模块，以有效地融合来自两个分支的多层次特征。Luo 等人[100] 也使用双向交叉注意来融合卷积运算提取的局部信息和自注意机制学习到的全局信息。Liu 等[101] 提出了 PHTrans，在深度阶段引入并行 hybird 模块，卷积块和修改后的 3D Swin Transformer 分别学习局部特征和全局依赖关系，然后通过序列到卷积操作统一输出的维度，实现特征聚合。</p>
<p>Zhou 等人[102]称，最近提出的大多数基于 Transformer 的分割方法只是将 Transformer 作为辅助模块，帮助在卷积表征中对全局上下文进行编码，而没有研究如何将自注意力与卷积进行优化组合。为了解决这个问题，他们引入了 nnFormer，这种交错架构基于自注意和卷积的经验组合。Xu 等人[99] 提出了 ECT-NAS 方法，基于多尺度空间搜索为医学图像分割搜索高效的 CNNTransformers 架构。</p>
<p>多尺度。MIA 中 Transformers 的多尺度策略以多尺度方式使用特征或以多尺度图像作为输入。</p>
<p>(1) 多分辨率图像。Zhang 等人[24] 提出了一种金字塔网络架构，即金字塔医学Transformer（PMTrans），它通过对多分辨率图像的处理来捕捉多范围关系。Valanarasu 等人[105] 在编码器中添加了门控轴向 Transformer 层，其中包含高度和宽度门控多头注意力块的基本构件。他们利用整幅图像和斑块来学习全局和局部特征，并提出了局部-全局训练策略（LoGo），以进一步提高整体性能。</p>
<p>(2) 多尺度特征。与 TransUNet 仅使用 Transformer 处理上一层学习到的低分辨率特征图不同，Xie 等人[25] 提出了一种可变形 Transformer（DeTrans）来处理多尺度和高分辨率特征图。Ji 等人[108] 提出了多尺度卷积Transformer（Multi-Compound Transformer，MCTrans），它将多尺度卷积特征嵌入为标记序列，并执行尺度内和尺度间的自注意。与这些使用 CNN 提取特征的研究不同，Hatamizadeh 等人[112] 引入了 UNEt Transformers（UNETR），利用纯 Transformer 作为编码器来学习输入卷的序列表示。Transformer 编码器通过不同分辨率的跳接直接连接到解码器，以计算最终的语义分割输出。Zhang 等人[122]提出了 S2WinTOUnet，利用星形 Window 自我注意力获取细粒度细节和粗粒度语义信息。</p>
<p>(3) 多层次注意。Chen 等人[114]提出了 TransAttUnet，其中多层次引导注意和多尺度跳转连接的联合设计有效增强了传统的 U 型架构。Transformer Self Attention（TSA）和 Global Spatial Attention（GSA）都被纳入 TransAttUnet，以有效学习编码特征之间的非局部交互。Wang 等人[118] 提出了混合Transformer模块（MTM），通过精心设计的局部-全局高斯加权自注意力（LGG-SA）计算自相似性，然后通过外部注意力（EA）挖掘数据样本之间的相互联系。Wu 等人[111]提出了 Dilated Transformer，对局部和全局范围内交替捕捉的成对补丁关系进行自注意。</p>
<p>(4) 多轴融合。Yan 等人[119]应用轴向融合 Transformer 融合了片间和片内信息，降低了在三维空间计算自注意的计算复杂度。</p>
<p>总之，上述方法都利用了通过特征融合策略学习到的附加特征，从而提高了学习效率。</p>
<h4 id="322-pure-transformer"><a class="markdownIt-Anchor" href="#322-pure-transformer"></a> 3.2.2 Pure Transformer</h4>
<p>除去上述结合了 Transformer 和卷积的 Unet 架构变体，Karimi 等人[123] 尝试在相邻图像补丁之间使用简单的自注意，而不进行卷积操作。三维图像被划分为 n3 个三维补丁（n = 3 或 5），每个补丁学习一个一维嵌入。网络通过对图像补丁嵌入之间的自我关注，输出中心补丁的分割结果。这种假设下的方法很容易被识别为纯粹的 Transformer。</p>
<p>Cao 等人[124]提出了一种用于医学图像分割的类 Unet 纯 Transformer，方法是将标记化的图像补丁送入类 Transformer 的 U 型编码器-解码器架构中，通过跳转连接以局部-全局的方式进行语义特征学习。Lin 等人[125] 更进一步提出了 DS-TransUNet，它首先采用基于 SwinTransformer 的双尺度编码器子网络来提取不同语义尺度的粗粒度和细粒度特征表征。同时，还提出了一个精心设计的 Transformer 交互融合（TIF）模块，通过自关注机制有效建立不同尺度特征之间的全局依赖关系。为了更好地利用 Transformer 的天然多尺度特征分层，Huang 等人[126] 提出了 MISSFormer，它有两个吸引人的设计： 1) 增强型 Transformer Block 作为前馈网络，具有更好的特征一致性、长距离依赖性和局部上下文；以及 2) 增强型 Transformer Context Bridge 用于对分层 Transformer 编码器生成的多尺度特征的长距离依赖性和局部上下文进行建模。</p>
<h3 id="33-image-to-image-translation"><a class="markdownIt-Anchor" href="#33-image-to-image-translation"></a> 3.3 Image-to-image translation</h3>
<p>Transformer 模型在图像合成 [16]、重建 [171] 和超分辨率 [172] 等许多图像到图像转换应用中也展示了其强大的学习能力。不过，在医学图像分析领域，最近开始出现图像到图像转换的研究成果（如 [26], [147]）。在此，我们在表 3 中列出了现有的基于 Transformer 的图像到图像转换方法及其评价指标。</p>
<h4 id="331-image-synthesis"><a class="markdownIt-Anchor" href="#331-image-synthesis"></a> 3.3.1 Image synthesis</h4>
<p>在医学领域，由于受试者之间的差异性以及解剖幻觉（如在脑部核磁共振成像中出现白点的幻觉）可能会对诊断任务造成损害，因此图像合成仍然非常具有挑战性。近年来，生成对抗学习被广泛用于处理图像合成任务。因此，Transformer 与生成对抗学习范式被结合起来用于图像合成。例如，Hu 等人[150] 提出了一种用于跨模态医学图像合成的双尺度判别器 GAN，由基于Transformer的全局判别器和基于 CNN 的局部判别器组成。Watanabe 等人[26]提出了一种基于 Transformer 解码块的生成模型架构，这得益于其在时间序列建模方面的强大能力。在数据处理过程中，他们通过特异性/非特异性结合率（SNBR）对单光子发射计算机断层扫描（SPECT）图像的像素值进行归一化处理。在训练过程中，他们采用 Transformer 解码器构建自动回归模型，并在帕金森病进行性标记主动数据库的[123 I]FP-CIT SPECT 图像上以非配对方式训练模型。训练后的模型能生成具有帕金森病患者特征的 SPECT 图像。Kamran 等人[147] 提出了一种基于 Transformer 的条件生成对抗网络，如图 9 所示，可同时执行从眼底照片到荧光素血管造影（FA）的半监督图像合成，用于视网膜疾病诊断。</p>
<p>针对正电子发射断层扫描（PET）的强度范围通常较宽且密集，甚至严重偏向零的问题，Shin 等人[149] 利用双向编码器表征（BERT），即 GANBERT，构建了一个生成式对抗网络，从 MRI 图像生成 PET 图像。Luo 等人[173] 提出了一种三维Transformer GAN，用于在低剂量下重建高质量 PET 图像。为了克服难以获得大型医疗数据集的限制，Korkmaz 等人[151] 引入了一种基于零点学习对抗Transformer（SLATER）的无监督重建方法来进行 MRI 合成。SLATER 是一种无条件对抗结构，由合成器、判别器和映射器组成。合成器采用交叉注意 Transformer 块来捕捉长程关系，映射器则将噪声和潜变量映射到 MR 图像上。Ristea 等人[153]提出了一种基于生成对抗卷积Transformer的架构–CyTran，并集成了周期一致性损失，用于对比度和非对比度 CT 扫描之间的非配对计算机断层扫描（CT）图像转换。</p>
<p>除了两种模态之间的图像合成工作，Transformer 模型还成功地应用于多模态医学图像合成。例如，Dalmaz 等人[154] 提出了一种用于多模态医学图像合成的生成对抗方法，即 ResViT。ResViT 中的生成器基于编码器-解码器架构，其中心瓶颈由能够协同保存局部和全局上下文的聚合残差Transformer（ART）块组成。</p>
<h4 id="332-image-super-resolution"><a class="markdownIt-Anchor" href="#332-image-super-resolution"></a> 3.3.2 Image super-resolution</h4>
<p>超分辨率成像（SR）是一类提高成像系统分辨率的技术，也是图像合成的一个热门子领域。Transformer 模型在医学图像分析的超分辨率任务上做出了突出贡献。例如，Feng 等人[159] 引入了一种任务 Transformer 网络（T2Net）来联合学习核磁共振成像中的图像重建和超分辨率任务。这是一个多任务框架，包括超分辨率分支和普通分辨率分支，作者设计了 Transformer 模块来嵌入相似性并对齐两个分支之间的差距。Zhang 等人[160] 提出了一种基于 Pyramid Transformer（PTNet）的高分辨率合成器，并用于婴儿大脑的 MRI 合成。PTNet 由执行编码器（PE）、执行解码器（PD）和 Transformer 瓶颈组成，后者继承了 U 结构以及多分辨率金字塔结构。</p>
<h4 id="333-image-denoising"><a class="markdownIt-Anchor" href="#333-image-denoising"></a> 3.3.3 Image denoising</h4>
<p>图像去噪是指去除图像中的噪声。它是多种临床应用的基本步骤。例如，Wang 等人[162] 首次将 Transformer 用于低剂量 CT（LDCT）去噪。他们开发了一种基于令牌到令牌（T2T）视觉 Transformer 的编码器-解码器去噪网络，即 TED-net。TED-net 也是一个 U 型结构模型，它利用 T2T 阶段的扩张来扩大感受野。Luthra 等人[164]提出了基于边缘增强的 Transformer（Eformer），它利用 Transformer 块构建了一个用于医学图像去噪的编码器-解码器架构。变压器模型及其在低剂量 CT（LDCT）去噪任务中的应用仍然很少。</p>
<h3 id="34-detection"><a class="markdownIt-Anchor" href="#34-detection"></a> 3.4 Detection</h3>
<p>在技术和临床领域，&quot;检测 &quot;的含义和术语各不相同。在技术领域，它通常指检查是否存在疾病或病变，而在临床实践中，它通常指诊断或疾病分类，如上所述。在计算机视觉领域，检测的目的是识别输入图像中物体的位置并预测其类别。在本节中，检测指的是物体检测的应用。</p>
<p>利用医学图像处理检测任务的 Transformer 通常与 CNN 块相结合，其中 CNN 用于从医学图像中提取特征，而 Transformer 架构则用于增强提取的特征，以便进行下游检测。Shen 等人[166] 提出了一种基于 DETR 的结肠息肉检测模型，即 COTR。DETR [14]是计算机视觉中物体检测的入门方法。COTR 由用于特征提取的 CNN、与卷积层交错的用于特征编码和重新校准的 Transformer 编码层、用于对象查询的 Transformer 解码层和用于检测预测的前馈网络组成。他们建议在 Transformer 编码器中插入卷积层，以实现高级图像特征重建和收敛加速。Ma 等人[167] 提出了一种结合 CNN 和 Transformer 网络的 TR 网络，用于检测多平面重新格式化（MPR）图像中的明显狭窄。他们的模型采用浅层 3D-CNN 提取冠状动脉区域的局部语义特征，同时确保模型的效率。接下来，利用 Transformer 编码器学习冠状动脉每个位置的局部狭窄不同区域之间的相关性。因此，在汇总局部语义特征和全局语义特征的信息后，TR-Net 可以准确地检测狭窄。Jiang 等人[165]构建了一个基于 YOLOv5s 的龋齿检测 Transformer，称为 RDFNet。该模型使用 FReLU 激活函数激活图像的复杂视觉空间信息，以提高效率。Kong 等人[168] 提出了一种用于 X 光图像端到端胸部异常检测的 contextaware 混合 Transformer–CT-CAD。Tao 等人[169] 设计了一种脊柱Transformer，用于解决任意视场脊柱 CT 中椎骨的自动检测和定位问题。他们将检测表述为一对一集合预测问题。</p>
<h3 id="35-registration"><a class="markdownIt-Anchor" href="#35-registration"></a> 3.5 Registration</h3>
<p>Transformer在图像配准任务中具有一些优势，这得益于它们的自我注意机制，这种机制可以在运动图像和固定图像之间实现更精确的空间映射。Chen 等人首创了用于图像配准的 Transformer。受 TransUnet [83] 架构的启发，他们提出了 ViT-V-Net [29]，通过简单改变 VoxelMorph（传统配准网络）[174] 的网络架构，将 ViT 和 V-Net 结合在一起。与基准方法相比，ViT-V-Net 的性能更胜一筹。之后，他们扩展了自己的工作，提出了用于体积医学影像配准的 TransMorph [175]。在这种方法中，Swin-Transformer[31] 被用作编码器网络，以捕捉输入移动图像和固定图像之间的空间对应关系。接着，ConvNet 解码器将Transformer编码器提供的信息映射到密集的位移场上。为了保持编码器和解码器阶段之间的本地信息流，采用了长跳接连接。显然，基于 Transformer 的配准方法并不多见，需要更多的探索和研究。</p>
<h3 id="36-video-based-applications"><a class="markdownIt-Anchor" href="#36-video-based-applications"></a> 3.6 Video-based applications</h3>
<p>由于感受野有限，CNN 无法充分利用连续视频帧中的全局时空信息，而 Transformer 则可以克服这种缺陷。Ji 等人[176] 提出了 PNS-Net（渐进归一化自注意网络），用于从结肠镜检查视频中准确分割息肉。Kondo 等人[177] 提出用 LapFormer 检测腹腔镜手术视频中的手术工具。Czempiel 等人[178] 采用 OperA 从长视频序列中预测手术阶段。Reynaud 等人[179] 首次采用了 Transformer 架构，该架构包含一个残差自动编码器网络和一个 BERT 模型，用于分析任意长度的视频。Long 等人[180] 首次应用 Transformer 估算手术场景深度。</p>
<h2 id="4-discussion"><a class="markdownIt-Anchor" href="#4-discussion"></a> 4 DISCUSSION</h2>
<p>Transformer 已成功应用于医学图像分析的几乎所有领域。然而，在实际临床应用中部署机器学习方法可能会因一些挑战而导致性能不佳。其中，最紧迫的挑战在于标签稀缺，尤其是在场景理解任务中，如分割和检测，通常需要像素级的精确标签。从有噪声的标签中学习是一个更大的挑战。此外，建立先进的 CADx 方法需要以多任务的方式使用多模态临床数据–尽管如此，这种通用的学习方法在设计上仍有困难。</p>
<h3 id="41-transformers-under-different-learning-scenarios"><a class="markdownIt-Anchor" href="#41-transformers-under-different-learning-scenarios"></a> 4.1 Transformers under different learning scenarios</h3>
<h4 id="411-multi-task-learning"><a class="markdownIt-Anchor" href="#411-multi-task-learning"></a> 4.1.1 Multi-task learning</h4>
<p>建立具有多重任务的模型有助于提高模型的通用性，而这正是医学图像分析领域所亟需的。一个常用的框架是将分类和分割统一为一个模型。[187], [188]. 例如，Chen 等人[188] 提出了多任务跨UNet（MT-TransUNet）来联合学习皮肤病变的分割和分类。通过 CNN 和 ViT 提取局部细节（如皮肤颜色、纹理）和长程上下文（如皮损形状、物理尺寸），该方法实现了 SOTA 性能，并在模型参数和推理速度方面获得了高效改进。此外，Sui 等人[189] 将检测任务与分割任务相结合，提出了一种新颖的迁移学习方法，即 CST，并采用基于 Transformer 的框架联合进行结直肠癌区域检测和肿瘤分割。在检测方面，输入图像生成的区域建议以及编码器-解码器模块获得的位置特征被用作 DETR 网络的输入。在分割方面，该模型使用图像片段作为输入，并将其投射到嵌入序列中。</p>
<h4 id="412-multi-modal-learning"><a class="markdownIt-Anchor" href="#412-multi-modal-learning"></a> 4.1.2 Multi-modal learning</h4>
<p>使用多种模式数据可为诊断提供互补证据。例如，研究人员探索了结合光学相干断层扫描（OCT）和视野（VF）测试来辅助诊断眼科疾病。Song 等人[71] 提出采用 Transformer 进行青光眼诊断。提出的模型利用注意力机制来模拟 OCT 特征和 VF 特征之间的配对关系。然后，再次应用注意力机制计算视野区域和视网膜神经纤维层象限之间的特征区域关系。利用 Transformer 模型将互补信息从一种模式传递到另一种模式。</p>
<p>Monajatipoor 等人[184] 提出了一种基于 Transformer 的视觉语言模型，该模型将高效的 PixelHop++ 模型与 BERT 模型相结合。具体来说，BERT 模型是利用领域内知识进行预训练的。事实证明，该模型在小规模数据集上的训练是有效的。提取的视觉特征和词嵌入被送入 Transformer 进行最终诊断。虽然该模型减少了对大量医学图像注释的需求，但语言模型的预训练仍需要大量临床报告。Jacenk ́ ow 等人[186] 将文本与 CXR 结合起来进行疾病分类。他们观察到，图像的解释和报告受扫描请求文本的影响，而扫描请求文本是放射报告中的指示字段。Zheng 等人[182] 通过考虑潜在的模态间相关性，重点研究了多模态信息的特征融合。他们提出了类似 Transformer 的模态注意特征融合方法（MaFF），在挖掘模态间关系的同时从每种模态中提取丰富的信息。然后，利用自适应图学习机制（AGL），基于融合特征为下游任务构建潜在鲁棒图。该方法大大提高了对注意力缺失症和自闭症的预测能力。Dai 等人[185] 提出了用于诊断腮腺肿瘤的 TransMed 方法。TransMed 结合了 CNN 和 Transformer 网络的优势，既能捕捉低级纹理，又能捕捉跨模态的高级关系。该模型首先将多模态图像处理为序列，通过链式处理并将其发送至 CNN 进行特征提取。然后将特征序列输入 Transformer，以学习序列之间的关系并进行特征融合。他们的研究利用 Transformer 从不同模态的图像中捕捉互信息，显示出更好的性能和效率。Nguyen 等人[181] 尝试模仿放射科医生和全科医生之间的互动，对膝关节骨关节炎进行诊断和预后判断。他们提出了一个具有三Transformer架构的临床启发多代理Transformer（CLIMAT）框架。首先，结合 Transformer 和 CNN 的特征提取器用于预测疾病的当前状态。接着，将非图像辅助信息输入另一个Transformer，以提取上下文嵌入。最后，另一个基于 Transformer 的全科医生模块会根据当前状态和上下文嵌入预测疾病轨迹。</p>
<p>总之，Transformer 被认为是连接 CV 和 NLP 任务的一种有前途的方法[190]。在此假设下，Radford 等人[191] 建立了一个多模态 Transformer，即 CLIP，它能在不进行图像标注的情况下，根据图像的文本描述识别图像，实现零误差能力。这种优势也为建立更强大、更准确的计算机辅助诊断（CADx）方法提供了潜在的途径，因为在实际临床应用中，多种数据类型（如临床、实验室和成像数据）都被视为不同的信息源。</p>
<h4 id="413-weakly-supervised-learning"><a class="markdownIt-Anchor" href="#413-weakly-supervised-learning"></a> 4.1.3 Weakly-supervised learning</h4>
<p>医学图像中的一种弱监督情况是，某种疾病的 ROI 在图像中相对较小，而只能进行图像级标记。为解决这一问题，多实例学习（MIL）被作为一种合适的解决方案。在多实例学习中，训练样本是一组实例，称为袋。只对包提供监督，而不提供包中所含实例的单个标签[200]。</p>
<p>尽管许多现有的 MIL 方法都假定正负实例是从正负分布中独立采样的 [200]，但包中的实例是相关的，尤其是在医学图像分析中。MIL 的学习场景并不遵循 i.i.d 假设，因为实例之间的关系不会被忽视。在这种情况下，可以利用 ViTs 来建立实例之间的相关性，从而获得更好的高层表征。Li 等人[192]提出了基于Transformer的 MIL 框架，其中的诱导关注块在计算关注度的同时，绕过了成对点乘所带来的二次计算复杂性。该框架的特征聚合器也是基于多头注意力。它将前面提到的特征合并成袋表示。Yang 等人[194] 将患者的多个肺结节视为一个包，每个结节视为一个实例。不同于传统的 MIL 方法使用池化操作来获得袋级表征，他们提出使用 3D DenseNet 在体素级学习单个结节级表征。接下来，生成的表示被输入 Transformer，以学习同一患者的结节关系。为了减轻计算负担，他们应用了从分裂通道特征中提取的组内缩放点生产注意力。Shao 等人[196] 重点研究了不同实例之间的相关性，而不是简单地假设实例是独立且同分布的。为此，他们提出了基于 Transformer 的 MIL 框架来处理整个幻灯片图像分类问题。他们的框架使用 Transformer 层来聚合形态信息，并提出了金字塔位置编码生成器（PPEG）来提取空间信息。此外，他们还采用 Nystrom 方法计算近似自注意力，从而将计算复杂度从 O(n2) 降低到 O(n)。Rymarczyk 等人[193] 对注意力机制给予了更多关注。他们的工作有助于修订基于注意力的 MIL 池（AbMILP），该方法可以聚合来自不同数量实例的信息。他们提出了基于注意力的自注意力 MILPooling（SA-AbMILP），以模拟袋中不同实例之间的依赖关系。他们还建议通过引入不同的内核来扩展注意力的计算，这些内核起到了与点生成相同的作用。他们在组织学、微生物学和视网膜数据集上评估了他们的工作。Yu 等人[195] 的研究探讨了 ViTs 在眼底图像视网膜疾病分类中的适用性。他们提出了多实例学习增强型视觉Transformer（MIL-VT），在 ViT 上添加了一个即插即用的多实例学习头，以利用从单个斑块中提取的特征。</p>
<p>另一个弱监督的例子是半监督学习，它只需要少量的标记数据，就能利用大量未标记数据中的知识。Luo 等人[201]首次将 CNN 和 Transformer 结合起来用于半监督医学图像分割。他们引入了 CNN 和 Transformer 之间的交叉教学，将一个网络的预测作为伪标签来监督另一个网络。Zhao 等人[202] 提出了一种名为 CA-Net 的上下文感知网络，用于从三维核磁共振图像中进行半监督 LA 分割。CA-Net 包含两个主要模块，一个是结合 Transformer 和 V-Net 来学习上下文信息的 Trans-V 模块，另一个是计算对抗损失的判别器，用于学习未标记的数据。Xiao 等人[203] 同时使用 CNN 和 Transformer 的 Dual-Teacher 结构来指导学生分割模型。</p>
<h4 id="414-self-supervised-learning"><a class="markdownIt-Anchor" href="#414-self-supervised-learning"></a> 4.1.4 Self-supervised learning</h4>
<p>Transformer 的成功训练依赖于大规模的注释数据，而这些数据在实际临床设施中很少能获得。自我监督学习（SSL）就是为了解决这一问题而诞生的。自我监督学习旨在通过转移相关无监督上游任务（即视觉概念学习）中的知识来提高下游任务（如分类、检测和分割）的性能，并利用未标注数据中的自含信息对模型进行预训练[204]。训练 SLL ViT 的做法一般是在 ImageNet 上对模型进行预训练，然后在目标医学图像数据集上进行微调。与 CNN 相比，这提高了 ViT 的性能，并达到了 SOTA 准确率[205]、[206]、[207]、[208]。</p>
<p>Truong 等人的研究[198] 评估了医疗图像中自监督特征的可转移性。他们使用自监督 ViT DINO 对特征进行了预训练。他们将 ViT 作为骨干，结果显示其与 SimCLR 和 SwAV 相比表现更优。Park 等人[43] 建议使用公开的大规模 CXR 分类数据集来预训练骨干网络。然后将预训练骨干网模型提取的特征输入 ViT，诊断 COVID-19。Jun 等人[129] 提出了一种自监督迁移学习框架，该框架能更好地表示三维容积图像中的空间关系，从而为下游任务提供便利。他们将三维容积图像转换成三视图的二维图像切片序列，并将其输入由卷积编码器和 Transformer 组成的预训练骨干网络。Transformer 的预训练通过屏蔽编码矢量实现，作为 SSL 的代理任务。下游任务包括利用三维容积图像进行脑疾病诊断、脑年龄预测和脑肿瘤分割。他们还为三维医学图像探索了一种参数高效的迁移学习框架。Wang 等人[197] 收集了一个大型公共组织病理学图像数据集，对他们提出的混合 CNN-Transformer 框架进行预训练。此外，他们还设计了标记聚集和激励（TAE）模块，通过考虑所有标记来进一步提高全局权重关注度。Sriram 等人[199] 探索了 Transformer 在 COVID-19 预后中的应用。他们提出了一个多图像预测 (MIP) 模型，将图像序列和相应的扫描时间作为输入。为了处理缺失的 COVID-19 图像，他们使用了动量对比学习（Momentum Contrast Learning），这是一种预训练特征提取网络的自我监督方法。除了从 X 射线中提取的特征外，他们还提出了连续位置嵌入（CPE）来添加基于时间步长的信息。特征和连续位置嵌入的串联被输入 Transformer，以预测不良事件发生的可能性。Chen 等人[209]的研究表明，使用基于 DINO 的知识提炼的视觉 Transformer 能够通过训练各种自监督模型，并在不同的弱监督组织表型任务上进行验证，从而学习组织学图像中数据高效且可解释的特征。值得注意的是，他们在学习不同形态表型的同时，还在 ViT 的不同注意头上发挥了出色的性能。</p>
<h3 id="42-model-improvement-quantification-acceleration-and-interpretation"><a class="markdownIt-Anchor" href="#42-model-improvement-quantification-acceleration-and-interpretation"></a> 4.2 Model-improvement: quantification, acceleration and interpretation</h3>
<p>在医学影像领域，有几项研究重点关注模型的效率。一个自然的思路是简化注意力机制，因为它是 Transformer 中工作量最大的部分。Gao 等人[89] 提出了一种高效的自我注意机制和位置编码，将自我注意操作的复杂度从 O(n2) 大幅降低到近似 O(n)。这规避了 Transformer 需要海量数据来学习视觉归纳偏差的障碍。他们的混合层设计将 Transformer 初始化为卷积网络，无需预训练。此外，Liu 等人[48] 采用的前述视觉展望器（VOLO）用展望关注取代了标准的自我关注，后者执行内部自我关注机制，降低了原有的时空复杂度。Li 等人[210] 在其作品 TransBTSV2 中重新设计了 Transformer 块，与传统的基于 Transformer 的方法相比，追求一种更浅但更宽的架构。Wu 等人[111] 受扩张卷积核的启发，以扩张的方式进行全局自注意，在不增加补丁的情况下扩大了感受野，降低了计算成本。Xu 等人[99] 构建了一个由多分支并行搜索块组成的多尺度搜索空间，并行连接 CNN 和 Transformer。他们还提出了一种高效的资源受限搜索策略，以同时优化模型的精度和成本（如参数和 FLOPs）。</p>
<p>我们看到，尝试在 MIA 而非 CV 中解决模型效率问题的作品较少。然而，随着医学影像尺寸越来越大、数量越来越少，该领域迫切需要解决这一问题。因此，我们希望在这个特定的研究方向上看到更多的作品。</p>
<h3 id="43-comparison-with-convolutional-neural-networks"><a class="markdownIt-Anchor" href="#43-comparison-with-convolutional-neural-networks"></a> 4.3 Comparison with convolutional neural networks</h3>
<p>在 ViTs 出现之前，卷积神经网络在 CV（包括医学图像分析领域）中占据主导地位。为了提高基于 CNN 的分类器在自然和医学图像中的性能，人们投入了大量精力。有几项研究提出了基于 CNN 的方法是否仍能在 ViTs 上发挥作用。同时，由于 ViTs 在多个基准测试中名列前茅，很多研究都集中在 ViTs 和 CNN 的性能比较上。要利用 Transformer 获得理想的性能，需要大规模的数据集。然而，在医学图像分析领域，可用的图像和注释非常有限。为了缓解这一问题，许多方法在 ViTs 中采用了卷积层来提高有限医学图像的性能，同时还利用了迁移学习和自我监督学习的力量。Matsoukas 等人[205]探讨了迁移学习和自我监督学习机制是否能使 ViTs 受益。他们使用不同的初始化策略进行了多项实验，比较了 CNN（即 ResNet50）和 ViT（即 DEIT-S）的性能： 1) 随机初始化权重；2) 使用 ImageNet 预训练权重进行迁移学习；3) 在目标数据集上进行自我监督预训练，并在 2) 中采用相同的初始化。他们在 APTOS 2019、ISIC 2019 和 CBIS-DDSM 数据集上对这些方法进行了评估。可以得出结论：标准程序，例如使用 ImageNet 预训练权重进行初始化，以及利用自监督学习，可以缩小 CNN 和 ViT 之间的性能差距。Krishnamurthy 等人[211] 在 CNN 和 ViT 中都采用了迁移学习方案来诊断肺炎。他们首先在 ImageNet 上对模型进行预训练，然后在自己的私人数据集上对分类器进行微调。然而，他们的比较是基于冻结骨干层的微调，这限制了适应目标领域时特征提取的性能。Truong 等人[198] 评估了医疗成像任务中自我监督特征的可转移性。他们选择 ResNet-50 作为骨干层，并使用 SimCLR、SwAV 和 DINO 三种自监督方法对其进行预训练。DINO 使用 ViT 作为骨干，其性能一直远远优于其他自监督技术和监督基线。他们提出了一种与模型无关的技术，即动态视觉元嵌入（DVME），将多种自我监督学习方法的预训练特征与自我关注相结合。针对多尺度细胞图像分类任务，Liu 等人[212] 提出了一个实验平台，用于比较多种深度学习方法，包括 CNN 和 ViT。他们通过改变图像的内部细胞比例，验证了深度学习模型在标准数据和缩放数据上的性能。结果表明，包括 ViTs 在内的深度学习模型对宫颈细胞病理学图像内部细胞比率的变化具有鲁棒性。在肩部植入物 X 光制造商分类方面，Zhou 等人[213] 比较了各种模型的性能，包括传统机器学习方法、基于 CNN 的深度学习方法和 ViTs。结果表明，ViT 在这些任务中取得了最佳性能，而迁移学习对 ViT 的改进幅度较大。Altay 等人[214] 的目标是利用磁共振成像对注意力缺失症进行早期临床前预测。他们将 Transformer 与基线三维 CNN 模型和三维递归视觉注意力模型进行了比较，结果表明 Transformer 实现了最佳的准确率和 F1 分数。AdjeiMensah 等人[215] 的研究表明，CNN 在低分辨率医学图像识别方面的表现优于 ViT。Galdran 等人[216] 的研究也表明，在少量数据的情况下，CNN 在糖尿病足溃疡分类方面的表现优于 ViT。总之，现有研究并未表明 ViTs 在所有情况下都优于 CNN，尤其是在少数据和低分辨率的医学图像分析中。因此，与计算机视觉中的方法类似，大多数最新研究都采用了用卷积建立混合模型的方法。</p>
<h2 id="5-conclusion"><a class="markdownIt-Anchor" href="#5-conclusion"></a> 5 CONCLUSION</h2>
<p>变形金刚正在改变计算机视觉领域。此外，在医学图像分析领域，使用Transformer的研究也在迅速发展。然而，目前大多数基于 Transformer 的方法都是自然而简单地应用于医学影像问题，并没有大的改变。换句话说，先进的方法，如弱监督学习、多模态学习、多任务学习和模型改进等，很少被探索。此外，我们只看到少数作品关注模型的一般问题，如并行化、可解释性、量化和安全性。这些都指明了医学 Transformer 的未来发展方向。</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">论文翻译</a></div><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/UNeXt/" title="UNeXt MLP-based Rapid Medical Image Segmentation Network"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">UNeXt MLP-based Rapid Medical Image Segmentation Network</div></div><div class="info-2"><div class="info-item-1"> UNeXt: MLP-based Rapid Medical Image Segmentation Network  摘要 UNet及其最新的扩展，如TransUNet，近年来一直是领先的医学图像分割方法。然而，这些网络不能有效地用于医疗点应用中的快速图像分割，因为它们的参数很高，计算复杂，使用缓慢。为此，我们提出了UNeXt，这是一个基于卷积多层感知器（MLP）的网络，用于图像分割。我们以一种有效的方式设计UNeXt，在早期卷积阶段和潜伏阶段的MLP阶段。我们提出了一个Tokenized 的MLP块，我们有效地标记和投影卷积特征，并使用MLPs来建模表示。为了进一步提高性能，我们建议在输入到MLP的过程中改变输入的通道，以便专注于学习局部依赖关系。在潜伏空间中使用Tokenized...</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/bisenetv1/" title="BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation</div></div><div class="info-2"><div class="info-item-1"> BiSeNet BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation  Abstract. 语义分割需要丰富的空间信息和相当大的感受野。然而，现代方法通常会牺牲空间分辨率来实现实时推理速度，这导致了性能不佳。在本文中，我们用一个新颖的双边分割网络（BiSeNet）来解决这个难题。我们首先设计了一个小步幅的空间路径，以保留空间信息并产生高分辨率的特征。同时，采用快速下采样策略的Context Path，以获得足够的感受野。在这两条路径的基础上，我们引入了一个新的特征融合模块来有效地结合特征。在Cityscapes、CamVid和COCO-Stuff数据集上，提议的架构在速度和分割性能之间取得了适当的平衡。具体来说，对于2048×1024的输入，我们在Cityscapes测试数据集上实现了68.4%的平均IOU，在一块NVIDIA Titan XP卡上的速度为105FPS，这比现有的具有可比性的方法要快得多。  1...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/AFFformer/" title="Head-Free Lightweight Semantic Segmentation with Linear Transformer"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">Head-Free Lightweight Semantic Segmentation with Linear Transformer</div></div><div class="info-2"><div class="info-item-1"> Head-Free Lightweight Semantic Segmentation with Linear Transformer  Abstract 现有的语义分割工作主要集中在设计有效的解码器上；然而，整体结构所带来的计算负荷长期以来一直被忽视，这阻碍了它们在资源有限的硬件上的应用。在本文中，我们提出了一个专门用于语义分割的无头轻量级架构，名为自适应频率变换器（AFFormer）。AFFormer采用了一个并行的架构来利用原型表征作为特定的可学习的局部描述，它取代了解码器并保留了高分辨率特征上丰富的图像语义。虽然去掉解码器后压缩了大部分的计算，但并行结构的准确性仍然受到低计算资源的限制。因此，我们采用异质运算器（CNN和Vision...</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Axial-attention/" title="AXIAL-ATTENTION"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">AXIAL-ATTENTION</div></div><div class="info-2"><div class="info-item-1"> AXIAL ATTENTION  ABSTRACT We propose Axial Transformers, a self-attention-based autoregressive model for images and other data organized as high dimensional tensors. Existing autoregressive models either suffer from excessively large computational resource requirements for high dimensional data, or make compromises in terms of distribution expressiveness or ease of implementation in order to decrease resource requirements. Our architecture, by contrast, maintains both full expressiveness...</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/ASGNet/" title="ASGNet"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">ASGNet</div></div><div class="info-2"><div class="info-item-1"> ASGNet  Abstract 原型学习被广泛应用于小样本分割。通常情况下，通过平均全局对象信息，从支持特征中获得单一原型。然而，使用一个原型来表示所有信息可能会导致模糊不清。在本文中，我们提出了两个用于多原型提取和分配的新型模块，分别名为超像素引导聚类（SGC）和引导原型分配（GPA）。具体来说，SGC 是一种无参数、无训练的方法，它通过聚合相似的特征向量来提取更具代表性的原型，而 GPA 则能够选择匹配的原型，从而提供更准确的指导。通过将 SGC 和 GPA 整合在一起，我们提出了自适应超像素引导网络 (ASGNet)，它是一种轻量级模型，能适应物体的比例和形状变化。此外，我们的网络还可以很容易地推广到 k 个镜头的分割，并在不增加计算成本的情况下实现大幅改进。特别是，我们在 COCO 上进行的评估表明，ASGNet 在 5 镜头分割方面比最先进的方法高出 5%。  1....</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/BAM/" title="BAM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">BAM</div></div><div class="info-2"><div class="info-item-1"> BAM  Abstract 近来，小样本分割分割技术（FSS）得到了广泛的发展。然而，训练出来的模型偏向于所看到的类别，而不是理想的类别无关性，从而阻碍了对新内容的识别。本文提出了一种新颖而直接的见解来缓解这一问题。具体来说，我们在传统的 FSS 模型（元学习器）上增加了一个分支（基础学习器），以明确识别基础类别的目标，即不需要分割的区域。然后，对这两个学习器并行输出的粗略结果进行自适应整合，从而得出精确的分割预测结果。考虑到元学习器的敏感性，我们进一步引入了一个调整因子来估计输入图像对之间的场景差异，以促进模型的集合预测。在 PASCAL-5i 和 COCO-20i 上取得的显著性能提升验证了这一方法的有效性，而且令人惊讶的是，即使使用两个普通学习器，我们的多功能方案也创造了新的一流水平。此外，鉴于所提方法的独特性，我们还将其扩展到了更现实但更具挑战性的环境中，即广义 FSS，在这种环境中，基础类和新类别的像素都需要确定。  1. Introduction   得益于成熟的大规模数据集 [8, 9,...</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Biformer/" title="BiFormer-Vision-Transformer-with-Bi-Level-Routing-Attention"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">BiFormer-Vision-Transformer-with-Bi-Level-Routing-Attention</div></div><div class="info-2"><div class="info-item-1">BiFormer: Vision Transformer with Bi-Level Routing Attention BiFormer: Vision Transformer with Bi-Level Routing Attention  2. Related Works Vision transformers. 变形器是一个神经网络家族，它采用信道明智的MLP块来进行每个位置的嵌入（信道混合），采用注意力[42]块来进行跨位置关系建模（空间混合）。变形器最初是为自然语言处理提出的[13, 42]，然后由DETR[1]和ViT[15]等开创性工作引入到计算机视觉。与CNN相比，最大的区别是，transformer使用注意力作为卷积的替代，以实现全局上下文建模。然而，由于香草注意计算所有空间位置的成对特征亲和力，它产生了高计算负担和沉重的内存足迹，特别是对于高分辨率输入。因此，一个重要的研究方向是寻求更有效的注意力机制。 Efficient attention mechanisms....</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Automatic-Classification-and-Segmentation-of-Teeth-on-3D-Dental-Model-Using-Hierarchical-Deep-Learning-Networks/" title="Automatic-Classification-and-Segmentation-of-Teeth-on-3D-Dental-Model-Using-Hierarchica-Deep-Learning-Network"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">Automatic-Classification-and-Segmentation-of-Teeth-on-3D-Dental-Model-Using-Hierarchica-Deep-Learning-Network</div></div><div class="info-2"><div class="info-item-1"> Automatic Classification and Segmentation of Teeth on 3D Dental Model Using Hierarchical Deep Learning Network Automatic Classification and Segmentation of Teeth on 3D Dental Model Using Hierarchical Deep Learning Network ...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/loading.gif" data-original="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qjl988</div><div class="author-info-description">钱家黎的博客</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">57</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qjl988"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qjl988" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/mjh1667002013" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=728831102&amp;website=www.oicqzone.com" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:1976083684@qq.com" target="_blank" title="Email"><i class="fas fa-email"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#transformers-in-medical-image-analysis-a-review"><span class="toc-text"> Transformers in Medical Image Analysis: A Review</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#abstract"><span class="toc-text"> Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-introduction"><span class="toc-text"> 1 INTRODUCTION</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-transformers"><span class="toc-text"> 2 TRANSFORMERS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-preliminaries"><span class="toc-text"> 2.1 Preliminaries</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#211-attention-mechanism"><span class="toc-text"> 2.1.1 Attention mechanism</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#212-attention-mechanism-in-computer-vision"><span class="toc-text"> 2.1.2 Attention mechanism in computer vision</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-architecture"><span class="toc-text"> 2.2 Architecture</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#221-encoder"><span class="toc-text"> 2.2.1 Encoder</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#222-decoder"><span class="toc-text"> 2.2.2 Decoder</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-vision-transformer"><span class="toc-text"> 2.3 Vision Transformer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-other-techniques"><span class="toc-text"> 2.4 Other techniques</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-transformers-in-medical-image-applications"><span class="toc-text"> 3 TRANSFORMERS IN MEDICAL IMAGE APPLICATIONS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-classification"><span class="toc-text"> 3.1 Classification</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#311-applications-of-pure-transformers"><span class="toc-text"> 3.1.1 Applications of pure Transformers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#312-applications-of-hybrid-transformers"><span class="toc-text"> 3.1.2 Applications of hybrid Transformers</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-segmentation"><span class="toc-text"> 3.2 Segmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#321-hybrid-transformers"><span class="toc-text"> 3.2.1 Hybrid Transformers</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#location-of-transformer-in-u-shaped-architecture"><span class="toc-text"> Location of Transformer in U-shaped architecture.</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#strategies-of-bridging-transformer-and-cnn"><span class="toc-text"> Strategies of bridging Transformer and CNN.</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#322-pure-transformer"><span class="toc-text"> 3.2.2 Pure Transformer</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-image-to-image-translation"><span class="toc-text"> 3.3 Image-to-image translation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#331-image-synthesis"><span class="toc-text"> 3.3.1 Image synthesis</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#332-image-super-resolution"><span class="toc-text"> 3.3.2 Image super-resolution</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#333-image-denoising"><span class="toc-text"> 3.3.3 Image denoising</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#34-detection"><span class="toc-text"> 3.4 Detection</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#35-registration"><span class="toc-text"> 3.5 Registration</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#36-video-based-applications"><span class="toc-text"> 3.6 Video-based applications</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-discussion"><span class="toc-text"> 4 DISCUSSION</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-transformers-under-different-learning-scenarios"><span class="toc-text"> 4.1 Transformers under different learning scenarios</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#411-multi-task-learning"><span class="toc-text"> 4.1.1 Multi-task learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#412-multi-modal-learning"><span class="toc-text"> 4.1.2 Multi-modal learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#413-weakly-supervised-learning"><span class="toc-text"> 4.1.3 Weakly-supervised learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#414-self-supervised-learning"><span class="toc-text"> 4.1.4 Self-supervised learning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-model-improvement-quantification-acceleration-and-interpretation"><span class="toc-text"> 4.2 Model-improvement: quantification, acceleration and interpretation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#43-comparison-with-convolutional-neural-networks"><span class="toc-text"> 4.3 Comparison with convolutional neural networks</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-conclusion"><span class="toc-text"> 5 CONCLUSION</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/11/%E5%B0%8F%E7%B1%B3/syzkaller/syzkaller01-%E9%85%8D%E7%BD%AE/" title="syzkaller01-配置">syzkaller01-配置</a><time datetime="2024-12-10T17:10:45.000Z" title="发表于 2024-12-11 01:10:45">2024-12-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/AFFformer/" title="Head-Free Lightweight Semantic Segmentation with Linear Transformer">Head-Free Lightweight Semantic Segmentation with Linear Transformer</a><time datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Axial-attention/" title="AXIAL-ATTENTION">AXIAL-ATTENTION</a><time datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/ASGNet/" title="ASGNet">ASGNet</a><time datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/BAM/" title="BAM">BAM</a><time datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By qjl988</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body></html>