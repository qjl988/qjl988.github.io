<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CariesNet | qjl988</title><meta name="author" content="qjl988"><meta name="copyright" content="qjl988"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="CariesNet: a deep learning approach for segmentation of multi-stage caries lesion from oral panoramic X-ray image  Abstract 龋齿一直是世界各地常见的健康问题，它甚至可以最终导致牙髓和根尖炎症。及时有效地治疗龋齿对患者减少痛苦至关重要。传统的龋齿疾病诊断方法，如肉眼检测和全景">
<meta property="og:type" content="article">
<meta property="og:title" content="CariesNet">
<meta property="og:url" content="https://qjl988.github.io/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/CariesNet/index.html">
<meta property="og:site_name" content="qjl988">
<meta property="og:description" content="CariesNet: a deep learning approach for segmentation of multi-stage caries lesion from oral panoramic X-ray image  Abstract 龋齿一直是世界各地常见的健康问题，它甚至可以最终导致牙髓和根尖炎症。及时有效地治疗龋齿对患者减少痛苦至关重要。传统的龋齿疾病诊断方法，如肉眼检测和全景">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qjl988.github.io/img/butterfly-icon.png">
<meta property="article:published_time" content="2024-12-10T15:28:34.000Z">
<meta property="article:modified_time" content="2024-12-10T16:58:10.747Z">
<meta property="article:author" content="qjl988">
<meta property="article:tag" content="论文翻译">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qjl988.github.io/img/butterfly-icon.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qjl988.github.io/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/CariesNet/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CariesNet',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/loading.gif" data-original="/img/butterfly-icon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">57</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qjl988</span></a><a class="nav-page-title" href="/"><span class="site-name">CariesNet</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">CariesNet</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-10T16:58:10.747Z" title="更新于 2024-12-11 00:58:10">2024-12-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">5.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="cariesnet-a-deep-learning-approach-for-segmentation-of-multi-stage-caries-lesion-from-oral-panoramic-x-ray-image"><a class="markdownIt-Anchor" href="#cariesnet-a-deep-learning-approach-for-segmentation-of-multi-stage-caries-lesion-from-oral-panoramic-x-ray-image"></a> CariesNet: a deep learning approach for segmentation of multi-stage caries lesion from oral panoramic X-ray image</h1>
<h2 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h2>
<p>龋齿一直是世界各地常见的健康问题，它甚至可以最终导致牙髓和根尖炎症。及时有效地治疗龋齿对患者减少痛苦至关重要。传统的龋齿疾病诊断方法，如肉眼检测和全景X光片检查，依赖于有经验的医生，这可能会导致误诊和高耗时。为此，我们提出了一种新型的深度学习架构，即CariesNet，以从全景射线照片中划分出不同的龋齿程度。我们首先收集了一个高质量的全景射线照片数据集，其中有3127个划线清晰的龋齿病变，包括浅度龋齿、中度龋齿和深度龋齿。然后，我们将CariesNet构建为一个U型网络，并增加了全尺寸轴向关注模块，以从口腔全景图像中分割这三种龋齿类型。此外，我们测试了CariesNet和其他基线方法的分割性能。实验表明，我们的方法在对三种不同程度的龋齿进行分割时，可以达到平均93.64%的Dice系数和93.61%的准确率。</p>
<h2 id="1-introduction"><a class="markdownIt-Anchor" href="#1-introduction"></a> 1 Introduction</h2>
<p>龋齿被定义为一种由牙菌斑中的微生物引起的影响牙齿硬组织的局部疾病[1]。它是最常见的口腔疾病之一。</p>
<p>根据2015年第四次中国全国口腔健康流行病学调查，3-5岁儿童原牙的龋齿患病率高达70.81%。随着年龄的增长，龋齿的发病率也逐步攀升。65-74岁年龄组的龋齿发病率为80.7%[2]。同时，龋齿造成了巨大的社会和经济负担。一项全球疾病负担研究显示，全球约有35亿人患有口腔疾病，治疗这些疾病的直接费用为2980亿美元[3]。</p>
<p>同时，龋齿的诊断取决于诊所医生的主观性。传统的龋齿诊断方法主要是由主治医生通过目测和探针探查发现，具有一定的主观性。鉴于早期龋齿和隐性龋齿难以被发现，误诊率很高。如果不及时治疗，龋齿可能会逐渐扩大，侵入牙髓，引发牙根炎、牙根脓肿等牙病，最终牙齿可能脱落。</p>
<p>口腔全景X光片（X射线）在诊断龋齿等牙科疾病方面发挥着关键作用。作为一种预防性的诊断工具，牙医可以利用口腔全景射线照片这一预防性的诊断工具来发现隐藏的牙齿结构、骨质流失、恶性或良性肿块以及目视检查下无法检查的龋齿。当牙齿结构有足够的脱钙时，龋齿的腐烂可以通过射线反映出来[1]。龋齿的X射线图像在不同的发展阶段显示不同的灰度值。根据[4]，浅龋是指釉质或牙本质外三分之一处的龋齿放射线；中度龋是指牙本质中间三分之一处的龋齿放射线；深龋是指牙本质内三分之一处的龋齿放射线，有或无明显牙髓受累。图1显示了一个全景X光片图像的例子。方框A、B和C分别对应于浅龋、中度龋和深龋。</p>
<p><img src="/img/loading.gif" data-original="http://qjl988-tuchuang.oss-cn-beijing.aliyuncs.com/typora/image-20230305194654743.png" alt="image-20230305194654743" /></p>
<blockquote>
<p>图1 全景射线照片中不同等级的龋齿病变实例：方框（a）中的浅龋，方框（b）中的中度龋和方框（c)中的深龋。</p>
</blockquote>
<p>计算机辅助诊断系统为解决上述问题提供了一种更有效的方法。通过计算机的分析和计算能力，建立了一个疾病诊断的数学模型。此外，对这类疾病的病变进行分类、预测和定位，可以大大减轻临床医生的负担，降低难度。近年来，随着人工智能的快速发展，这项技术在医学影像领域也得到了普及，而深度学习是在人工智能领域应用最多的，基于医学影像大数据集的自动学习，其手段是引入卷积神经网络（CNN）来提取图像特征。</p>
<p>在本文中，为了达到对龋齿病变的精确分割，我们提出了一个新的深度学习网络，称为CariesNet。受U-Net[5]结构的启发，我们建立了一个用于口腔全景图像分割的U型神经网络。特别是，我们使用了全面的轴向注意力模块以及部分编码器模块来提高分割性能。总而言之，这项工作的主要贡献有三个方面。</p>
<p>(1) 我们提出了一个新的深度架构CariesNet，用于分割全景射线照片中的龋齿病变。</p>
<p>(2) 我们提出了全尺寸轴向注意（FSSA）模块，以提高小尺寸病变分割的稳健性。</p>
<p>(3) 提出的CariesNet达到了93.64%的平均Dice相似性系数（DSC），并在收集的数据集上显示出有效的结果。</p>
<p>本文的其余部分组织如下。第2节简要回顾了相关工作。我们提出的CariesNet方法在第3节中描述。3. 第4节报告了实验结果。最后，第5节总结了这项工作。</p>
<h2 id="2-related-works"><a class="markdownIt-Anchor" href="#2-related-works"></a> 2 Related works</h2>
<h3 id="21-computer-aided-diagnosis-methods-for-dental-caries"><a class="markdownIt-Anchor" href="#21-computer-aided-diagnosis-methods-for-dental-caries"></a> 2.1 Computer-aided diagnosis methods for dental caries</h3>
<p>该计算机系统可用于量化图像中灰度值的变化，实现临床诊断。近年来，深度学习也被应用于识别和诊断龋齿。2016年，Anias等通过阈值分割从口腔全景X射线图像中提取48个感兴趣的区域，利用神经网络结合BP反向传播来诊断龋齿[6]。Ali等人使用三个堆叠的稀疏自动编码器来提取牙尖的特征，并应用Softmax分类器来判断牙齿是否有龋齿[7]。2017年，引入线性自适应粒子群优化（LA-PSO）算法，对120幅蛀牙全景图像生成l-rate，并通过反向传播神经模型对所提LA-PSO的分类性能进行评估[8]。Prajapati等人引入迁移技术，构建了基于卷积神经网络的龋齿诊断模型，使用VGG-16检测251张X射线图像中的龋齿[9]；Zhang等人构建了基于CBCT图像的计算机辅助评估系统，以提高龋齿诊断的准确性[10]。2020年，Lin等人构建了基于深度学习模型的计算机辅助龋齿诊断系统，结果表明深度学习在检测根尖X射线图像中的龋齿方面具有良好的性能，可以检测根尖X射线图像中恒牙的邻面龋齿，为邻面龋齿的早期诊断提供参考[11]。Haghanifar等人收集了480张口腔全景X射线图像，提出了牙齿分割和龋齿检测工作流程，达到了90.52%的龋齿检测准确率[12]。然而，收集高质量的龋齿数据集和建立一个高效的深度学习架构仍然是巨大的挑战。</p>
<h3 id="22-deep-learning-methods-for-image-segmentation"><a class="markdownIt-Anchor" href="#22-deep-learning-methods-for-image-segmentation"></a> 2.2 Deep learning methods for image segmentation</h3>
<p>在口腔医学中，已经提出了许多计算机辅助图像分割的方法（见[13，14]对此类方法的全面回顾）。与自然图像中的处理类似，深度学习已被广泛地应用于计算机视觉任务，如图像分类和物体检测[15]。最近，越来越多的基于深度学习的方法被开发用于图像分割。其中一个典型的方法是全连接网络（FCN）可以进行端到端的分割，并在不同的图像应用中有效（例如，语义分割[16，17]，视频对象检测[18，19]，多模式分类[20]）。然而，由于其完全连接的结构，FCN使用了大量的参数，因此在模型训练中产生了障碍。SegNet[21]提出了一个编码器-解码器结构，以加速训练过程。在FCN和SegNet的基础上，一个改进的网络U-Net[5]采用了编码器-解码器结构，并在上采样层和下采样层之间使用跳过连接，将高分辨率的特征与上采样的输出相结合。为了提高性能，人们还提出了一些U-Net的变体，如3D U-Net[22]、V-Net[23]、UNet? [24]、SE-ResUnet[25]和注意U-Net[26]。特别是Fan等人[27]提出了高效网络PraNet来平衡推理速度和分割性能。</p>
<p>除了上述已知的一般图像分割框架，一些专门的深度学习模型也被开发出来。具体来说，对于X射线图像的分割，已经设计了多个基于深度学习的模型。Al-Antari等人直接使用DeepLab进行现场分割[28]。Blain等人提出了一个改良的U-Net网络来检测胸部X光图像中的COVID-19感染[29]。Moeskops等人利用不同的图像模式来训练一个多任务分割模型[30]。Trullo等人将条件随机场模块的结构作为RNN引入FCN[31]。此外，深度学习方法在其他医学图像分割任务中也取得了明显的成功，如细胞[32]、头颈部（HaN）[33]、肝脏[34]、大脑[35]和视盘[36]的分割。</p>
<h2 id="3-materials-and-methods"><a class="markdownIt-Anchor" href="#3-materials-and-methods"></a> 3 Materials and methods</h2>
<h3 id="31-overview"><a class="markdownIt-Anchor" href="#31-overview"></a> 3.1 Overview</h3>
<p>在本节中，我们展示了拟议中的龋齿网络的工作流程。我们首先解释了收集全面的口腔全景X射线图像数据集的过程。接着，我们介绍了CariesNet的架构以及全尺度轴向关注（FSSA）模块。最后我们解释损失函数和模型训练的细节。</p>
<h3 id="32-dataset-preparation"><a class="markdownIt-Anchor" href="#32-dataset-preparation"></a> 3.2 Dataset preparation</h3>
<p>在使用X射线的牙齿问题检测领域的大多数相关研究在他们的数据集中缺乏足够数量的图像。大型数据集让模型拥有更复杂的架构，包括更多的参数。因此，开发的模型可以处理更复杂的特征，并检测牙齿纹理中出现的细微异常，如早期阶段的龋齿。注释是一个重要但耗时的部分，需要由现场专家（如牙医或放射科医生）来完成。</p>
<p>为了解决数据缺乏的问题，我们试图建立一个高质量的口腔全景数据集。浙江大学医学院附属口腔医院从2015年至2020年收集了一组源于牙科治疗和常规护理的1159幅全景图像。数据收集得到了中华口腔医学会伦理委员会的伦理批准。数据集中只包括恒牙的全景图像。原生牙的全景图像或那些被认为不可能进行任何评估的图像被排除在外。大部分数据都是使用制造商Dentsply Sirona（德国Bensheim）的放射机产生的，主要是Orthophos XG。在所有的全景图像上，每颗牙齿都由三位牙医使用FDI方案进行分割和标记，并由第四位牙医检查。从1159张口腔全景图像中，3217个龋齿区域被标记为浅度龋齿、中度龋齿或深度龋齿。我们的龋齿数据集的详情见表1。</p>
<p><img src="/img/loading.gif" data-original="images/image-20230709130710956.png" alt="image-20230709130710956" /></p>
<h3 id="33-cariesnet-overall-architecture"><a class="markdownIt-Anchor" href="#33-cariesnet-overall-architecture"></a> 3.3 CariesNet overall architecture</h3>
<p>一般来说，口腔全景照片的尺寸很大，而目标龋齿区域很小。如图2所示，找到并划定网络的整体架构是一个挑战。我们设计CariesNet的灵感来自于PraNet[27]的整体架构，它是基于反向注意机制的[37]。如图2所示，CariesNet是一个通用的U型编码器-解码器框架，它可以聚合从多级卷积网络中提取的特征。传统的U型网络只是简单地将特征传递给每个解码器层，而一些高层次的上下文信息可能会在解码器中丢失。与文献[27]中的介绍类似，我们使用部分解码器来聚合CariesNet中更多的高层特征。在本文中，我们利用Res2Net[38]作为一个有效的骨干网。我们将骨干网中的三个高级特征图串联到部分解码器中，它可以预测出龋齿的初始显著性图，在图2中被标记为全局图。然后，骨干特征和部分解码器特征都被串联到注意力模块中。在CariesNet中，我们用全尺寸轴向注意（FSAA）模块取代了反向注意（RA）模块，FSAA的细节在第3.4节中描述。3.4. 接下来，特征图通过1 1卷积层并与之前的FSAA全局图相加。此外，在每个高层中，前一层的FSAA得到的特征图和骨干的特征图也被串联起来作为FSAA的输入。我们使用三个后续的FSAA来计算高层的显著性地图。最后，使用带有sigmoid函数的4次双线性上采样变换来获得全局特征图的最终输出。</p>
<p>龋齿网络能有效地从口腔全景X光图像中分割出轻微的龋齿区域。通过在部分解码器中聚合三个高层的特征，可以有效地从全局图中提取上下文信息，这意味着可以将目标龋齿病变置于初始指导区域（全局图）。全面的轴向注意力模块可以进一步挖掘输出分割结果的边界线索。综上所述，整体架构显示，Res2Net骨干特征被转发到部分解码器以生成初始全局图，而全面的轴向注意力模块可以重建准确的龋齿分割结果。</p>
<p><img src="/img/loading.gif" data-original="images/image-20230305223539742.png" alt="image-20230305223539742" /></p>
<blockquote>
<p>图2 龋齿的结构示意图，它由三个全尺寸的轴向注意模块和一个部分解码器组成</p>
</blockquote>
<h3 id="34-full-scale-axial-attention-module"><a class="markdownIt-Anchor" href="#34-full-scale-axial-attention-module"></a> 3.4 Full-scale axial attention module</h3>
<p>一般来说，对于有经验的医生来说，目标龋齿病变的划定包括两个步骤。首先，对可能包含目标病变的粗略区域进行定位。而第二步是注释出目标区域的准确边界。由于粗略的显著性图是由部分解码器得到的，我们提出了可以挖掘边界线索的FSSA模块。上述模块可以提取细粒度的特征图，其中既有高层次的语义信息，又有低层次的细节信息。</p>
<p>如图3所示，输入的高层次骨干特征图和上采样的位置图首先被连接起来。与普通的轴向注意模块不同，为了使该模块能够整合更多层次的特征信息，我们同时考虑了平均池化和最大池化。提取的通道域特征通过全连接层再次映射到与原始特征图像通道数相同的维度上，而空间域特征则通过逐元卷积核的卷积层进行映射，得到与空间特征相同大小的单通道特征。我们从通道域和空间域平行提取注意力特征，然后让网络通过元素-明智卷积层将这两个特征聚合起来。为了得到一个更平滑的注意力特征图，我们在融合层之后利用一个sigmoid层。FSAA最终输出了一个注意力特征图，从全局角度代表了上下文信息。</p>
<p><img src="/img/loading.gif" data-original="images/image-20230709130742715.png" alt="image-20230709130742715" /></p>
<h3 id="35-learning-process-and-implementation-details"><a class="markdownIt-Anchor" href="#35-learning-process-and-implementation-details"></a> 3.5 Learning process and implementation details</h3>
<p><strong>损失函数</strong> 通常采用二元交叉熵（BCE）作为损失函数，可以表述如下。</p>
<p><img src="/img/loading.gif" data-original="http://qjl988-tuchuang.oss-cn-beijing.aliyuncs.com/typora/image-20230306003635570.png" alt="image-20230306003635570" /></p>
<p>其中f是像素数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">m_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">n_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>分别表示预测值和其对应的groundtruth值。然而，由于交叉熵损失函数对类别不平衡的敏感性很高，由此产生的低效率优化需要自适应损失函数。因此，在我们的模型中使用Dice损失作为损失函数，具体如下：</p>
<p><img src="/img/loading.gif" data-original="images/image-20230709130905039.png" alt="image-20230709130905039" /></p>
<p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">m_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>是预测值，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">n_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>是相应的GroundTruth。</p>
<p>我们在CariesNet中结合BCE损失和Dice损失，最终的损失函数可以表示为：：</p>
<p><img src="/img/loading.gif" data-original="images/image-20230709130912853.png" alt="image-20230709130912853" /></p>
<p><strong>实施细节</strong> 我们在训练数据中所有512 512大小的口腔全景图像上用200个epochs训练龋齿网络。我们使用Adam作为优化器，初始学习率为1e-4，在80、120和150个历时中衰减。我们的实验是在配备英特尔（R）至强（R）CPU E5-2630 v4 @ 2.20GHz、256GB内存和8x NVIDIA GeForce 2080TiGPU与12GB GPU内存的工作站平台上进行。该代码是在Ubuntu 18.04中用PyTorch 1.3.1实现的。</p>
<h2 id="4-experiments-and-discussion"><a class="markdownIt-Anchor" href="#4-experiments-and-discussion"></a> 4 Experiments and discussion</h2>
<h3 id="41-evaluation-metrics"><a class="markdownIt-Anchor" href="#41-evaluation-metrics"></a> 4.1 Evaluation metrics</h3>
<p>采用一些评价指标，包括Dice系数、准确性、精确性和召回率，来比较CariesNet和其他方法的表现，以比较不同方法的表现。Dice系数衡量龋齿自动分割和人工分割之间的重叠像素，其计算方法如下：</p>
<p><img src="/img/loading.gif" data-original="images/image-20230625230316441.png" alt="image-20230625230316441" /></p>
<p>其中TP、FP、TN和FN分别代表真阳性、假阳性、真阴性和假阴性预测。准确度是指龋齿类型和背景分割的全部准确度，其描述如下：</p>
<p><img src="/img/loading.gif" data-original="images/image-20230625230300234.png" alt="image-20230625230300234" /></p>
<p>精确率是指在自动分割的龋齿病变的所有像素中，被划分为真阳性区域的比例，其定义如下：</p>
<p><img src="/img/loading.gif" data-original="images/image-20230625230337194.png" alt="image-20230625230337194" /></p>
<p>召回率是指通过自动分割分类的龋齿区域的真阳性像素与通过手工分割分类的龋齿病变像素的比例，计算如下：</p>
<p><img src="/img/loading.gif" data-original="images/image-20230625230346823.png" alt="image-20230625230346823" /></p>
<p>F1分值用于量化龋齿病变在精确率和召回率之间的加权平均值，其值在[0，1]，计算公式如下：</p>
<p><img src="/img/loading.gif" data-original="images/image-20230625230405029.png" alt="image-20230625230405029" /></p>
<h3 id="42-comparative-experiments"><a class="markdownIt-Anchor" href="#42-comparative-experiments"></a> 4.2 Comparative experiments</h3>
<p>表2中报告了从龋齿数据集中获得的结果。在每个测试案例中，我们将口腔全景图像分成两部分，即左边和右边。关于测试结果的评估，两部分的联合分割结果被合并了。DeepLab是一个被广泛使用的像素级分割工具[39]，它也使用了一个编码器-解码器结构。这里，我们使用U-Net和DeepLabV3+作为基线模型。我们使用Res-Unet[40]中的Res2Net作为骨干，它也作为骨干方法实现了消融实验。所有的深度学习模型都在相同的验证集上进行测试，DSC、准确率、F1得分、精度和召回率的结果分别见表2。很明显，PraNet和CariesNet模型在使用部分解码模块定位目标病变方面表现良好，而CariesNet以较大的幅度提高了整体性能。普通U-Net和DeepLabv3的表现与骨干方法Res-Unet相似。Attention-UNet的分割结果要好得多，它证明了注意力机制可以显著提高模型的性能。同时，CariesNet的表现优于最先进的方法PraNet，因为全面的轴向注意力模块可以捕获广泛而有效的上下文信息。CariesNet最终取得了93.64%的DSC。</p>
<p><img src="/img/loading.gif" data-original="images/image-20230709124516321.png" alt="image-20230709124516321" /></p>
<h3 id="43-ablation-study"><a class="markdownIt-Anchor" href="#43-ablation-study"></a> 4.3 Ablation study</h3>
<p>除了上述与最先进的方法的比较，我们还进行了大量的消融实验来验证我们的方法的有效性，包括部分编码器模块，全面的轴向注意力模块，BCE/Dice损失函数和深度监督策略。如表3所示，在对三种类型的龋齿进行分割时，报告了每个模型的Dice系数。很明显，FSAA可以显著提高模型的性能。此外，我们注意到在中度龋齿的划分上性能相对较低，因为无论是深龋和中度龋齿的边界还是浅龋和中度龋齿的边界都相对模糊，模型容易将中度龋齿误判为浅龋或深龋。尽管CariesNet在中度龋上显示出的性能比骨架有限，但它有助于改善深龋上约11.1%的DSC和浅龋上12.4%的DSC。</p>
<p><img src="/img/loading.gif" data-original="images/image-20230709124226180.png" alt="image-20230709124226180" /></p>
<h3 id="44-results-visualization"><a class="markdownIt-Anchor" href="#44-results-visualization"></a> 4.4 Results visualization</h3>
<p>图2显示了分割的结果。CariesNet可以很好地从口腔全景射线照片中找到小的龋齿病灶。在图4中，我们将深龋病灶标记为黄色部分。中度龋坏和浅度龋坏区域分别被标记为蓝色和绿色部分。为了清楚地比较两种方法之间的性能，我们选择一个部分来放大显示。CariesNet、PraNet、U-Net、DeepLabv3和Res-U-Net的分割结果显示在图4。与其他方法相比，CariesNet的边界更平滑、更准确。</p>
<p><img src="/img/loading.gif" data-original="images/image-20230709124425696.png" alt="image-20230709124425696" /></p>
<h2 id="5-conclusion"><a class="markdownIt-Anchor" href="#5-conclusion"></a> 5 Conclusion</h2>
<p>总之，我们开发了一个自动化的龋齿诊断系统。实验证明，深度学习模型可以有效地从口腔全景X光图像中分割出龋齿病变。特别是，我们开发了一个最先进的分割网络CariesNet，将部分编码器模块和全面的轴向注意力模块实现为共同的编码器-解码器U型结构。我们在数据集上进行了实验，验证和测试研究显示了我们的新方法在这个分割任务中的能力。比较和消融实验也表明，我们的新龋齿网络结构在从大的X射线图像中分割轻微病变方面产生了非常好的性能。</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">论文翻译</a></div><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/DAPPM(DDRNet)/" title="Deep Dual-resolution Networks for Real-time and Accurate Semantic Segmentation of Road Scenes"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Deep Dual-resolution Networks for Real-time and Accurate Semantic Segmentation of Road Scenes</div></div><div class="info-2"><div class="info-item-1"> 用于实时和准确道路场景语义分割的深度双分辨率网络 Deep Dual-resolution Networks for Real-time and Accurate Semantic Segmentation of Road Scenes  Abstract 语义分割是自动驾驶汽车理解周围场景的关键技术。当代模型的迷人性能通常是以繁重的计算和漫长的推理时间为代价的，这对于自动驾驶来说是无法忍受的。利用轻量级架构（编码器-解码器或双通道）或在低分辨率图像上进行推理，最近的方法实现了非常快速的场景解析，甚至可以在单个1080Ti GPU上以超过100...</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/CBL/" title="CBL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">CBL</div></div><div class="info-2"><div class="info-item-1"> 3. Effective Number of Samples We formulate the data sampling process as a simplified version of random covering. The key idea is to associate each sample with a small neighboring region instead of a single point. We present our theoretical framework and the formulation of calculating effective number of samples.  3.1. Data Sampling as Random Covering Given a class, denote the set of all possible data in the feature space of this class as S. We assume the volume of S is N and N ≥ 1. Denote...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/AFFformer/" title="Head-Free Lightweight Semantic Segmentation with Linear Transformer"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">Head-Free Lightweight Semantic Segmentation with Linear Transformer</div></div><div class="info-2"><div class="info-item-1"> Head-Free Lightweight Semantic Segmentation with Linear Transformer  Abstract 现有的语义分割工作主要集中在设计有效的解码器上；然而，整体结构所带来的计算负荷长期以来一直被忽视，这阻碍了它们在资源有限的硬件上的应用。在本文中，我们提出了一个专门用于语义分割的无头轻量级架构，名为自适应频率变换器（AFFormer）。AFFormer采用了一个并行的架构来利用原型表征作为特定的可学习的局部描述，它取代了解码器并保留了高分辨率特征上丰富的图像语义。虽然去掉解码器后压缩了大部分的计算，但并行结构的准确性仍然受到低计算资源的限制。因此，我们采用异质运算器（CNN和Vision...</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Axial-attention/" title="AXIAL-ATTENTION"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">AXIAL-ATTENTION</div></div><div class="info-2"><div class="info-item-1"> AXIAL ATTENTION  ABSTRACT We propose Axial Transformers, a self-attention-based autoregressive model for images and other data organized as high dimensional tensors. Existing autoregressive models either suffer from excessively large computational resource requirements for high dimensional data, or make compromises in terms of distribution expressiveness or ease of implementation in order to decrease resource requirements. Our architecture, by contrast, maintains both full expressiveness...</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/ASGNet/" title="ASGNet"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">ASGNet</div></div><div class="info-2"><div class="info-item-1"> ASGNet  Abstract 原型学习被广泛应用于小样本分割。通常情况下，通过平均全局对象信息，从支持特征中获得单一原型。然而，使用一个原型来表示所有信息可能会导致模糊不清。在本文中，我们提出了两个用于多原型提取和分配的新型模块，分别名为超像素引导聚类（SGC）和引导原型分配（GPA）。具体来说，SGC 是一种无参数、无训练的方法，它通过聚合相似的特征向量来提取更具代表性的原型，而 GPA 则能够选择匹配的原型，从而提供更准确的指导。通过将 SGC 和 GPA 整合在一起，我们提出了自适应超像素引导网络 (ASGNet)，它是一种轻量级模型，能适应物体的比例和形状变化。此外，我们的网络还可以很容易地推广到 k 个镜头的分割，并在不增加计算成本的情况下实现大幅改进。特别是，我们在 COCO 上进行的评估表明，ASGNet 在 5 镜头分割方面比最先进的方法高出 5%。  1....</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/BAM/" title="BAM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">BAM</div></div><div class="info-2"><div class="info-item-1"> BAM  Abstract 近来，小样本分割分割技术（FSS）得到了广泛的发展。然而，训练出来的模型偏向于所看到的类别，而不是理想的类别无关性，从而阻碍了对新内容的识别。本文提出了一种新颖而直接的见解来缓解这一问题。具体来说，我们在传统的 FSS 模型（元学习器）上增加了一个分支（基础学习器），以明确识别基础类别的目标，即不需要分割的区域。然后，对这两个学习器并行输出的粗略结果进行自适应整合，从而得出精确的分割预测结果。考虑到元学习器的敏感性，我们进一步引入了一个调整因子来估计输入图像对之间的场景差异，以促进模型的集合预测。在 PASCAL-5i 和 COCO-20i 上取得的显著性能提升验证了这一方法的有效性，而且令人惊讶的是，即使使用两个普通学习器，我们的多功能方案也创造了新的一流水平。此外，鉴于所提方法的独特性，我们还将其扩展到了更现实但更具挑战性的环境中，即广义 FSS，在这种环境中，基础类和新类别的像素都需要确定。  1. Introduction   得益于成熟的大规模数据集 [8, 9,...</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Biformer/" title="BiFormer-Vision-Transformer-with-Bi-Level-Routing-Attention"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">BiFormer-Vision-Transformer-with-Bi-Level-Routing-Attention</div></div><div class="info-2"><div class="info-item-1">BiFormer: Vision Transformer with Bi-Level Routing Attention BiFormer: Vision Transformer with Bi-Level Routing Attention  2. Related Works Vision transformers. 变形器是一个神经网络家族，它采用信道明智的MLP块来进行每个位置的嵌入（信道混合），采用注意力[42]块来进行跨位置关系建模（空间混合）。变形器最初是为自然语言处理提出的[13, 42]，然后由DETR[1]和ViT[15]等开创性工作引入到计算机视觉。与CNN相比，最大的区别是，transformer使用注意力作为卷积的替代，以实现全局上下文建模。然而，由于香草注意计算所有空间位置的成对特征亲和力，它产生了高计算负担和沉重的内存足迹，特别是对于高分辨率输入。因此，一个重要的研究方向是寻求更有效的注意力机制。 Efficient attention mechanisms....</div></div></div></a><a class="pagination-related" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Automatic-Classification-and-Segmentation-of-Teeth-on-3D-Dental-Model-Using-Hierarchical-Deep-Learning-Networks/" title="Automatic-Classification-and-Segmentation-of-Teeth-on-3D-Dental-Model-Using-Hierarchica-Deep-Learning-Network"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="info-item-2">Automatic-Classification-and-Segmentation-of-Teeth-on-3D-Dental-Model-Using-Hierarchica-Deep-Learning-Network</div></div><div class="info-2"><div class="info-item-1"> Automatic Classification and Segmentation of Teeth on 3D Dental Model Using Hierarchical Deep Learning Network Automatic Classification and Segmentation of Teeth on 3D Dental Model Using Hierarchical Deep Learning Network ...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/loading.gif" data-original="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qjl988</div><div class="author-info-description">钱家黎的博客</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">57</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qjl988"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qjl988" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/mjh1667002013" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=728831102&amp;website=www.oicqzone.com" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:1976083684@qq.com" target="_blank" title="Email"><i class="fas fa-email"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#cariesnet-a-deep-learning-approach-for-segmentation-of-multi-stage-caries-lesion-from-oral-panoramic-x-ray-image"><span class="toc-text"> CariesNet: a deep learning approach for segmentation of multi-stage caries lesion from oral panoramic X-ray image</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#abstract"><span class="toc-text"> Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-introduction"><span class="toc-text"> 1 Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-related-works"><span class="toc-text"> 2 Related works</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-computer-aided-diagnosis-methods-for-dental-caries"><span class="toc-text"> 2.1 Computer-aided diagnosis methods for dental caries</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-deep-learning-methods-for-image-segmentation"><span class="toc-text"> 2.2 Deep learning methods for image segmentation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-materials-and-methods"><span class="toc-text"> 3 Materials and methods</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-overview"><span class="toc-text"> 3.1 Overview</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-dataset-preparation"><span class="toc-text"> 3.2 Dataset preparation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-cariesnet-overall-architecture"><span class="toc-text"> 3.3 CariesNet overall architecture</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#34-full-scale-axial-attention-module"><span class="toc-text"> 3.4 Full-scale axial attention module</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#35-learning-process-and-implementation-details"><span class="toc-text"> 3.5 Learning process and implementation details</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-experiments-and-discussion"><span class="toc-text"> 4 Experiments and discussion</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-evaluation-metrics"><span class="toc-text"> 4.1 Evaluation metrics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-comparative-experiments"><span class="toc-text"> 4.2 Comparative experiments</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#43-ablation-study"><span class="toc-text"> 4.3 Ablation study</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#44-results-visualization"><span class="toc-text"> 4.4 Results visualization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-conclusion"><span class="toc-text"> 5 Conclusion</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/11/%E5%B0%8F%E7%B1%B3/syzkaller/syzkaller01-%E9%85%8D%E7%BD%AE/" title="syzkaller01-配置">syzkaller01-配置</a><time datetime="2024-12-10T17:10:45.000Z" title="发表于 2024-12-11 01:10:45">2024-12-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/AFFformer/" title="Head-Free Lightweight Semantic Segmentation with Linear Transformer">Head-Free Lightweight Semantic Segmentation with Linear Transformer</a><time datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/Axial-attention/" title="AXIAL-ATTENTION">AXIAL-ATTENTION</a><time datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/ASGNet/" title="ASGNet">ASGNet</a><time datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/10/%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/BAM/" title="BAM">BAM</a><time datetime="2024-12-10T15:28:34.000Z" title="发表于 2024-12-10 23:28:34">2024-12-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By qjl988</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body></html>